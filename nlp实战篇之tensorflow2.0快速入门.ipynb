{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s?__biz=MzIwODI2NDkxNQ==&mid=2247489340&idx=3&sn=197a57a12954ad4284ab083488342397&chksm=97049c80a0731596d7579466c6844931cd41b8bcb101c7ffb076abfe32c767cc506d6975c943&scene=126&sessionid=1593141601&key=f9077bed3f45e74f988ce8319873edc5b241c70876b516087171441cd121edc0f830c3d617bca92a8674bd3164edf3c117d5e0090900dac7877e8ef6292633619a760a35bfa19296d43ae0bcbf81d337&ascene=1&uin=MjA1MjAyODkxNg%3D%3D&devicetype=Windows+10+x64&version=6209051a&lang=zh_CN&exportkey=AUH%2B%2Fy8DNYIDM%2F0pFJuceXI%3D&pass_ticket=nkufbuZ2D6vSURECYdsr2t3GiiqSA3OjPYMwQpdvEoQBiuvtCxGyPYv9wNqyLZP7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 25000\n",
      "test len: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 下载IMDB数据\n",
    "vocab_size = 10000 # 保留词的个数\n",
    "imdb = tf.keras.datasets.imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=vocab_size)\n",
    "print(\"train len:\", len(train_data))    # [25000]\n",
    "print(\"test len:\", len(test_data))    # [25000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重构词的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个将单词映射到整数索引的词典\n",
    "word_index = imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 简单预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一文本序列长度\n",
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,value=word_index[\"<PAD>\"],padding=\"post\",truncating=\"post\",maxlen=256)\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,value=word_index[\"<PAD>\"],padding=\"post\",truncating=\"post\",maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,16),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, 16)\n",
    "        self.g_avg_pool = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.d1 = tf.keras.layers.Dense(16, activation=\"relu\")\n",
    "        self.d2 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # inputs: [batch_size, seq_len]\n",
    "        x = self.embedding(inputs)    # [batch_size, seq_len, 16]\n",
    "        x = self.g_avg_pool(x)    # [batch_size, 16]\n",
    "        x = self.d1(x)    # [batch_size, 16]\n",
    "        x = self.d2(x)    # [batch_size, 1]]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.6912 - binary_accuracy: 0.5518\n",
      "Epoch 2/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.6794 - binary_accuracy: 0.7257\n",
      "Epoch 3/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.6461 - binary_accuracy: 0.7657\n",
      "Epoch 4/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.5858 - binary_accuracy: 0.7993\n",
      "Epoch 5/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.5105 - binary_accuracy: 0.8289\n",
      "Epoch 6/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.4400 - binary_accuracy: 0.8542\n",
      "Epoch 7/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.3845 - binary_accuracy: 0.8688\n",
      "Epoch 8/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.3439 - binary_accuracy: 0.8791\n",
      "Epoch 9/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.3137 - binary_accuracy: 0.8876\n",
      "Epoch 10/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.2900 - binary_accuracy: 0.8950\n",
      "Epoch 11/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2709 - binary_accuracy: 0.9023\n",
      "Epoch 12/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2553 - binary_accuracy: 0.9065\n",
      "Epoch 13/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2410 - binary_accuracy: 0.9121\n",
      "Epoch 14/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2292 - binary_accuracy: 0.9181\n",
      "Epoch 15/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.2182 - binary_accuracy: 0.9226\n",
      "Epoch 16/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2089 - binary_accuracy: 0.9252\n",
      "Epoch 17/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1997 - binary_accuracy: 0.9292\n",
      "Epoch 18/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1917 - binary_accuracy: 0.9327\n",
      "Epoch 19/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1843 - binary_accuracy: 0.9349: 0s - loss: 0.1780 - binary_accuracy:\n",
      "Epoch 20/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1774 - binary_accuracy: 0.9378\n",
      "Epoch 21/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1713 - binary_accuracy: 0.9402: 0s - loss: 0.1712 - binary_accuracy: 0.94\n",
      "Epoch 22/40\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1654 - binary_accuracy: 0.9428\n",
      "Epoch 23/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1594 - binary_accuracy: 0.9454\n",
      "Epoch 24/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1538 - binary_accuracy: 0.9482\n",
      "Epoch 25/40\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1489 - binary_accuracy: 0.9503\n",
      "Epoch 26/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1439 - binary_accuracy: 0.9521\n",
      "Epoch 27/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1389 - binary_accuracy: 0.9540\n",
      "Epoch 28/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1344 - binary_accuracy: 0.9561\n",
      "Epoch 29/40\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1303 - binary_accuracy: 0.9582\n",
      "Epoch 30/40\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1265 - binary_accuracy: 0.9595\n",
      "Epoch 31/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1223 - binary_accuracy: 0.9621\n",
      "Epoch 32/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1182 - binary_accuracy: 0.9633\n",
      "Epoch 33/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1146 - binary_accuracy: 0.9645\n",
      "Epoch 34/40\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1114 - binary_accuracy: 0.9660\n",
      "Epoch 35/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.1077 - binary_accuracy: 0.9676\n",
      "Epoch 36/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1047 - binary_accuracy: 0.9688\n",
      "Epoch 37/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.1012 - binary_accuracy: 0.9700\n",
      "Epoch 38/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0983 - binary_accuracy: 0.9715\n",
      "Epoch 39/40\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0957 - binary_accuracy: 0.9724\n",
      "Epoch 40/40\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0931 - binary_accuracy: 0.9733\n",
      "782/782 - 0s - loss: 0.4249 - binary_accuracy: 0.8554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4248790740966797, 0.855400025844574]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 配置模型训练参数\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),loss=tf.keras.losses.BinaryCrossentropy(),metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "# 训练模型\n",
    "history = model.fit(train_data,train_labels,epochs=40,batch_size=512)\n",
    "# 评估测试集\n",
    "model.evaluate(test_data,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型的保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.6931 - accuracy: 0.5066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931140422821045, 0.506600022315979]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存权重\n",
    "model.save_weights(\"../dataset/my_checkpoint\")\n",
    "# 加载权重\n",
    "new_model = MyModel()\n",
    "# 预测之前需要先编译\n",
    "new_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "new_model.load_weights(\"../dataset/my_checkpoint\")\n",
    "# 评估测试集\n",
    "new_model.evaluate(test_data,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hdf5方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 15:54:47.591032 31260 hdf5_format.py:201] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "782/782 - 0s - loss: 0.4249 - binary_accuracy: 0.8554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4248790740966797, 0.855400025844574]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只能用户functional model or a sequential model，目前不能用于subclass model\n",
    "# 保存模型\n",
    "model.save(\"../dataset/my_model.h5\")\n",
    "# 加载模型\n",
    "# 重新创建完全相同的模型，包括其权重和优化程序\n",
    "new_model = tf.keras.models.load_model(\"../dataset/my_model.h5\")\n",
    "# 显示网格结构\n",
    "new_model.summary()\n",
    "# 评估测试集\n",
    "new_model.evaluate(test_data,test_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "tf.saved_model.save(model,'../dataset/test_model')\n",
    "# 加载模型\n",
    "new_model = tf.saved_model.load('../dataset/test_model')\n",
    "# 预测结果\n",
    "result = new_model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
