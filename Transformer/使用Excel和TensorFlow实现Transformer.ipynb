{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mp.weixin.qq.com/s?__biz=MzI3ODgwODA2MA==&mid=2247486745&idx=2&sn=f3da20a636aa52bc0c1f3219077aaf97&chksm=eb50198adc27909c9c823becf952ca762e991fca51381d61c98fdb328dc81be6890173a70f67&mpshare=1&scene=2&srcid=&from=timeline#rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_embedding = tf.constant([[0.11,0.21,0.31,0.41],\n",
    "                         [0.21,0.31,0.41,0.51],\n",
    "                         [0.31,0.41,0.51,0.61],\n",
    "                         [0.41,0.51,0.61,0.71]],dtype=tf.float32)\n",
    "english_embedding = tf.constant([[0.51,0.61,0.71,0.81],\n",
    "                         [0.52,0.62,0.72,0.82],\n",
    "                         [0.53,0.63,0.73,0.83],\n",
    "                         [0.54,0.64,0.74,0.84]],dtype=tf.float32)\n",
    "position_encoding = tf.constant([[0.01,0.01,0.01,0.01],\n",
    "                         [0.02,0.02,0.02,0.02],\n",
    "                         [0.03,0.03,0.03,0.03],\n",
    "                         [0.04,0.04,0.04,0.04]],dtype=tf.float32)\n",
    "encoder_input = tf.constant([[0,1,2,3],[2,3,0,1]],dtype=tf.int32)\n",
    "with tf.variable_scope('encoder_input'):\n",
    "    encoder_embedding_input = tf.nn.embedding_lookup(chinese_embedding,encoder_input)\n",
    "    encoder_embedding_input = encoder_embedding_input + position_encoding\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run([encoder_embedding_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Block\n",
    "with tf.variable_scope('encoder_scaled_dot_product_attention'):\n",
    "    encoder_Q = tf.matmul(tf.reshape(encoder_embedding_input,(-1,tf.shape(encoder_embedding_input)[2])),w_Q)\n",
    "    encoder_K = tf.matmul(tf.reshape(encoder_embedding_input,(-1,tf.shape(encoder_embedding_input)[2])),w_K)\n",
    "    encoder_V = tf.matmul(tf.reshape(encoder_embedding_input,(-1,tf.shape(encoder_embedding_input)[2])),w_V)\n",
    "    \n",
    "    encoder_Q = tf.reshape(encoder_Q,(tf.shape(encoder_embedding_input)[0],tf.shape(encoder_embedding_input)[1],-1))\n",
    "    encoder_K = tf.reshape(encoder_K,(tf.shape(encoder_embedding_input)[0],tf.shape(encoder_embedding_input)[1],-1))\n",
    "    encoder_V = tf.reshape(encoder_V,(tf.shape(encoder_embedding_input)[0],tf.shape(encoder_embedding_input)[1],-1))\n",
    "                          \n",
    "                          \n",
    "    attention_map = tf.matmul(encoder_Q,tf.transpose(encoder_K,[0,2,1]))\n",
    "    attention_map = attention_map / 8\n",
    "    attention_map = tf.nn.softmax(attention_map)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(attention_map))\n",
    "    print(sess.run(encoder_first_sa_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
