{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/jaimezorno/Deep-Learning-for-NLP-Creating-a-Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sandra',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'office', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sandra went back to the hallway . Sandra moved to the office .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the office ?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for story,question,answer in train_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1\n",
    "# vocab_len = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = (max(all_story_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# vectorizing the data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'put': 2,\n",
       " 'journeyed': 3,\n",
       " 'daniel': 4,\n",
       " '?': 5,\n",
       " 'hallway': 6,\n",
       " 'moved': 7,\n",
       " 'to': 8,\n",
       " '.': 9,\n",
       " 'apple': 10,\n",
       " 'took': 11,\n",
       " 'up': 12,\n",
       " 'mary': 13,\n",
       " 'there': 14,\n",
       " 'kitchen': 15,\n",
       " 'bedroom': 16,\n",
       " 'left': 17,\n",
       " 'got': 18,\n",
       " 'in': 19,\n",
       " 'milk': 20,\n",
       " 'football': 21,\n",
       " 'back': 22,\n",
       " 'office': 23,\n",
       " 'sandra': 24,\n",
       " 'went': 25,\n",
       " 'down': 26,\n",
       " 'garden': 27,\n",
       " 'grabbed': 28,\n",
       " 'travelled': 29,\n",
       " 'picked': 30,\n",
       " 'is': 31,\n",
       " 'discarded': 32,\n",
       " 'no': 33,\n",
       " 'bathroom': 34,\n",
       " 'dropped': 35,\n",
       " 'john': 36,\n",
       " 'yes': 37}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for vectorizing the stories, questions and answers:\n",
    "def vectorize_stories(data,word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\n",
    "    #vectorized stories:\n",
    "    X = []\n",
    "    #vectorized questions:\n",
    "    Xq = []\n",
    "    #vectorized answers:\n",
    "    Y = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        #Getting indexes for each word in the story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        #Getting indexes for each word in the story\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        #For the answers\n",
    "        y = np.zeros(len(word_index) + 1) #Index 0 Reserved when padding the sequences\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    #Now we have to pad these sequences:\n",
    "    return(pad_sequences(X,maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 13,  7,  8,  1, 34,  9, 24,  3,  8,\n",
       "        1, 16,  9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 7, 8, 1, 34, 9, 24, 3, 8, 1, 16, 9]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Network\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input,Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create the placeholders \n",
    "#The Input function is used to create a keras tensor\n",
    "#PLACEHOLDER shape = (max_story_len,batch_size)\n",
    "#These are our placeholder for the inputs, ready to recieve batches of the stories and the questions\n",
    "input_sequence = Input((max_story_len,)) #As we dont know batch size yet\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder M:\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (Samples, story_maxlen,embedding_dim) -- Gives a list of the lenght of the samples where each item has the\n",
    "#lenght of the max story lenght and every word is embedded in the embbeding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder C:\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_len)) #From paper\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create question encoder:\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_len)) #From paper\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, question_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets encode the sequences, passing the placeholders into our encoders:\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use dot product to compute similarity between input encoded m and question \n",
    "#Like in the paper:\n",
    "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the response we want to add this match with the ouput of input_encoded_c\n",
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have the response we can concatenate it with the question encoded:\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the answer tensor with a RNN (LSTM)\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization with dropout:\n",
    "answer = Dropout(0.5)(answer)\n",
    "#Output layer:\n",
    "answer = Dense(vocab_len)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to output a probability distribution for the vocab, using softmax:\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the final model:\n",
    "model = Model([input_sequence,question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#Categorical instead of binary cross entropy as because of the way we are training\n",
    "#we could actually see any of the words from the vocab as output\n",
    "#however, we should only see yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.8634 - acc: 0.4943 - val_loss: 0.6949 - val_acc: 0.5030\n",
      "Epoch 2/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.7012 - acc: 0.4959 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 3/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.6959 - acc: 0.4992 - val_loss: 0.6935 - val_acc: 0.5030\n",
      "Epoch 4/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.6955 - acc: 0.4940 - val_loss: 0.6932 - val_acc: 0.4720\n",
      "Epoch 5/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.6948 - acc: 0.4937 - val_loss: 0.6939 - val_acc: 0.5030\n",
      "Epoch 6/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.6948 - acc: 0.4975 - val_loss: 0.6932 - val_acc: 0.4910\n",
      "Epoch 7/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.6944 - acc: 0.4985 - val_loss: 0.6938 - val_acc: 0.4980\n",
      "Epoch 8/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.6939 - acc: 0.5052 - val_loss: 0.6942 - val_acc: 0.4840\n",
      "Epoch 9/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.6939 - acc: 0.5026 - val_loss: 0.6961 - val_acc: 0.4990\n",
      "Epoch 10/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.6925 - acc: 0.5172 - val_loss: 0.6950 - val_acc: 0.4840\n",
      "Epoch 11/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.6786 - acc: 0.5648 - val_loss: 0.6429 - val_acc: 0.6540\n",
      "Epoch 12/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.5679 - acc: 0.7213 - val_loss: 0.4637 - val_acc: 0.7910\n",
      "Epoch 13/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.4600 - acc: 0.7992 - val_loss: 0.4216 - val_acc: 0.8150\n",
      "Epoch 14/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.4232 - acc: 0.8236 - val_loss: 0.4125 - val_acc: 0.8370\n",
      "Epoch 15/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.3891 - acc: 0.8384 - val_loss: 0.4009 - val_acc: 0.8360\n",
      "Epoch 16/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.3758 - acc: 0.8443 - val_loss: 0.3990 - val_acc: 0.8180\n",
      "Epoch 17/1000\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.3589 - acc: 0.8510 - val_loss: 0.3785 - val_acc: 0.8360\n",
      "Epoch 18/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3555 - acc: 0.8515 - val_loss: 0.3635 - val_acc: 0.8370\n",
      "Epoch 19/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.3407 - acc: 0.8576 - val_loss: 0.3568 - val_acc: 0.8350\n",
      "Epoch 20/1000\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.3375 - acc: 0.8569 - val_loss: 0.3682 - val_acc: 0.8390\n",
      "Epoch 21/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.3332 - acc: 0.8589 - val_loss: 0.3480 - val_acc: 0.8370\n",
      "Epoch 22/1000\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.3269 - acc: 0.8583 - val_loss: 0.3417 - val_acc: 0.8380\n",
      "Epoch 23/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3243 - acc: 0.8625 - val_loss: 0.3408 - val_acc: 0.8460\n",
      "Epoch 24/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.3195 - acc: 0.8638 - val_loss: 0.3480 - val_acc: 0.8420\n",
      "Epoch 25/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3176 - acc: 0.8652 - val_loss: 0.3464 - val_acc: 0.8430\n",
      "Epoch 26/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.3158 - acc: 0.8633 - val_loss: 0.3378 - val_acc: 0.8450\n",
      "Epoch 27/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.3191 - acc: 0.8607 - val_loss: 0.3379 - val_acc: 0.8500\n",
      "Epoch 28/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.3123 - acc: 0.8632 - val_loss: 0.3433 - val_acc: 0.8400\n",
      "Epoch 29/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.3084 - acc: 0.8667 - val_loss: 0.3366 - val_acc: 0.8410\n",
      "Epoch 30/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.3078 - acc: 0.8655 - val_loss: 0.3389 - val_acc: 0.8320\n",
      "Epoch 31/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.3069 - acc: 0.8643 - val_loss: 0.3563 - val_acc: 0.8410\n",
      "Epoch 32/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.3063 - acc: 0.8654 - val_loss: 0.3426 - val_acc: 0.8300\n",
      "Epoch 33/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.3017 - acc: 0.8684 - val_loss: 0.3413 - val_acc: 0.8480\n",
      "Epoch 34/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.3004 - acc: 0.8665 - val_loss: 0.3372 - val_acc: 0.8410\n",
      "Epoch 35/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.3020 - acc: 0.8710 - val_loss: 0.3481 - val_acc: 0.8520\n",
      "Epoch 36/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2984 - acc: 0.8688 - val_loss: 0.3373 - val_acc: 0.8510\n",
      "Epoch 37/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.2979 - acc: 0.8689 - val_loss: 0.3282 - val_acc: 0.8440\n",
      "Epoch 38/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2971 - acc: 0.8682 - val_loss: 0.3325 - val_acc: 0.8420\n",
      "Epoch 39/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2937 - acc: 0.8711 - val_loss: 0.3328 - val_acc: 0.8490\n",
      "Epoch 40/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.2943 - acc: 0.8747 - val_loss: 0.3467 - val_acc: 0.8430\n",
      "Epoch 41/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.2901 - acc: 0.8711 - val_loss: 0.3474 - val_acc: 0.8440\n",
      "Epoch 42/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2890 - acc: 0.8714 - val_loss: 0.3268 - val_acc: 0.8370\n",
      "Epoch 43/1000\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.2895 - acc: 0.8731 - val_loss: 0.3284 - val_acc: 0.8460\n",
      "Epoch 44/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2903 - acc: 0.8709 - val_loss: 0.3359 - val_acc: 0.8460\n",
      "Epoch 45/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2898 - acc: 0.8727 - val_loss: 0.3374 - val_acc: 0.8440\n",
      "Epoch 46/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.2888 - acc: 0.8745 - val_loss: 0.3468 - val_acc: 0.8420\n",
      "Epoch 47/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2867 - acc: 0.8723 - val_loss: 0.3292 - val_acc: 0.8450\n",
      "Epoch 48/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.2859 - acc: 0.8735 - val_loss: 0.3404 - val_acc: 0.8370\n",
      "Epoch 49/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2835 - acc: 0.8779 - val_loss: 0.3301 - val_acc: 0.8410\n",
      "Epoch 50/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.2826 - acc: 0.8724 - val_loss: 0.3449 - val_acc: 0.8410\n",
      "Epoch 51/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.2836 - acc: 0.8767 - val_loss: 0.3344 - val_acc: 0.8380\n",
      "Epoch 52/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2799 - acc: 0.8770 - val_loss: 0.3340 - val_acc: 0.8370\n",
      "Epoch 53/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.2781 - acc: 0.8768 - val_loss: 0.3498 - val_acc: 0.8430\n",
      "Epoch 54/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2783 - acc: 0.8804 - val_loss: 0.3581 - val_acc: 0.8460\n",
      "Epoch 55/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2757 - acc: 0.8768 - val_loss: 0.3588 - val_acc: 0.8450\n",
      "Epoch 56/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.2764 - acc: 0.8802 - val_loss: 0.3583 - val_acc: 0.8360\n",
      "Epoch 57/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.2729 - acc: 0.8819 - val_loss: 0.3606 - val_acc: 0.8400\n",
      "Epoch 58/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2768 - acc: 0.8799 - val_loss: 0.3620 - val_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.2739 - acc: 0.8778 - val_loss: 0.3459 - val_acc: 0.8390\n",
      "Epoch 60/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2774 - acc: 0.8799 - val_loss: 0.3537 - val_acc: 0.8360\n",
      "Epoch 61/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.2777 - acc: 0.8773 - val_loss: 0.3491 - val_acc: 0.8370\n",
      "Epoch 62/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.2719 - acc: 0.8838 - val_loss: 0.3661 - val_acc: 0.8430\n",
      "Epoch 63/1000\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.2689 - acc: 0.8812 - val_loss: 0.3538 - val_acc: 0.8410\n",
      "Epoch 64/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.2698 - acc: 0.8793 - val_loss: 0.3572 - val_acc: 0.8390\n",
      "Epoch 65/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2663 - acc: 0.8831 - val_loss: 0.3538 - val_acc: 0.8410\n",
      "Epoch 66/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2611 - acc: 0.8859 - val_loss: 0.3638 - val_acc: 0.8410\n",
      "Epoch 67/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2638 - acc: 0.8841 - val_loss: 0.3631 - val_acc: 0.8400\n",
      "Epoch 68/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2627 - acc: 0.8852 - val_loss: 0.3552 - val_acc: 0.8430\n",
      "Epoch 69/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2615 - acc: 0.8867 - val_loss: 0.3727 - val_acc: 0.8380\n",
      "Epoch 70/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2646 - acc: 0.8861 - val_loss: 0.3699 - val_acc: 0.8400\n",
      "Epoch 71/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.2590 - acc: 0.8856 - val_loss: 0.3659 - val_acc: 0.8480\n",
      "Epoch 72/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.2603 - acc: 0.8876 - val_loss: 0.3687 - val_acc: 0.8380\n",
      "Epoch 73/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2561 - acc: 0.8905 - val_loss: 0.3608 - val_acc: 0.8480\n",
      "Epoch 74/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2508 - acc: 0.8903 - val_loss: 0.3832 - val_acc: 0.8510\n",
      "Epoch 75/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2482 - acc: 0.8944 - val_loss: 0.3699 - val_acc: 0.8470\n",
      "Epoch 76/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.2470 - acc: 0.8986 - val_loss: 0.3527 - val_acc: 0.8520\n",
      "Epoch 77/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2406 - acc: 0.9000 - val_loss: 0.3829 - val_acc: 0.8550\n",
      "Epoch 78/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2397 - acc: 0.8969 - val_loss: 0.3626 - val_acc: 0.8500\n",
      "Epoch 79/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2368 - acc: 0.9038 - val_loss: 0.3504 - val_acc: 0.8490\n",
      "Epoch 80/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.2283 - acc: 0.9028 - val_loss: 0.3488 - val_acc: 0.8540\n",
      "Epoch 81/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2252 - acc: 0.9036 - val_loss: 0.3326 - val_acc: 0.8660\n",
      "Epoch 82/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.2166 - acc: 0.9074 - val_loss: 0.3654 - val_acc: 0.8660\n",
      "Epoch 83/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.2130 - acc: 0.9118 - val_loss: 0.3179 - val_acc: 0.8700\n",
      "Epoch 84/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.2043 - acc: 0.9134 - val_loss: 0.3136 - val_acc: 0.8780\n",
      "Epoch 85/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1983 - acc: 0.9169 - val_loss: 0.3258 - val_acc: 0.8710\n",
      "Epoch 86/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1888 - acc: 0.9212 - val_loss: 0.3001 - val_acc: 0.8800\n",
      "Epoch 87/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.1851 - acc: 0.9240 - val_loss: 0.3121 - val_acc: 0.8780\n",
      "Epoch 88/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1757 - acc: 0.9246 - val_loss: 0.2748 - val_acc: 0.8880\n",
      "Epoch 89/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1727 - acc: 0.9311 - val_loss: 0.2818 - val_acc: 0.8800\n",
      "Epoch 90/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.1654 - acc: 0.9312 - val_loss: 0.2685 - val_acc: 0.8840\n",
      "Epoch 91/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.1592 - acc: 0.9356 - val_loss: 0.2679 - val_acc: 0.8960\n",
      "Epoch 92/1000\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.1608 - acc: 0.9353 - val_loss: 0.2874 - val_acc: 0.8860\n",
      "Epoch 93/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.1606 - acc: 0.9381 - val_loss: 0.2744 - val_acc: 0.8860\n",
      "Epoch 94/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.1509 - acc: 0.9409 - val_loss: 0.2916 - val_acc: 0.9000\n",
      "Epoch 95/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.1514 - acc: 0.9393 - val_loss: 0.2517 - val_acc: 0.8990\n",
      "Epoch 96/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.1426 - acc: 0.9453 - val_loss: 0.3120 - val_acc: 0.8940\n",
      "Epoch 97/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1338 - acc: 0.9463 - val_loss: 0.2684 - val_acc: 0.8950\n",
      "Epoch 98/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.1398 - acc: 0.9470 - val_loss: 0.2714 - val_acc: 0.8950\n",
      "Epoch 99/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.1427 - acc: 0.9458 - val_loss: 0.2657 - val_acc: 0.9020\n",
      "Epoch 100/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.1308 - acc: 0.9468 - val_loss: 0.2573 - val_acc: 0.8970\n",
      "Epoch 101/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.1271 - acc: 0.9489 - val_loss: 0.2845 - val_acc: 0.8960\n",
      "Epoch 102/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.1311 - acc: 0.9482 - val_loss: 0.2635 - val_acc: 0.8970\n",
      "Epoch 103/1000\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.1253 - acc: 0.9499 - val_loss: 0.2651 - val_acc: 0.9040\n",
      "Epoch 104/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1247 - acc: 0.9482 - val_loss: 0.2624 - val_acc: 0.8950\n",
      "Epoch 105/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1257 - acc: 0.9509 - val_loss: 0.2580 - val_acc: 0.8990\n",
      "Epoch 106/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1290 - acc: 0.9467 - val_loss: 0.2891 - val_acc: 0.9060\n",
      "Epoch 107/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.1173 - acc: 0.9527 - val_loss: 0.2548 - val_acc: 0.9010\n",
      "Epoch 108/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.1225 - acc: 0.9520 - val_loss: 0.2731 - val_acc: 0.9010\n",
      "Epoch 109/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.1161 - acc: 0.9541 - val_loss: 0.2748 - val_acc: 0.9030\n",
      "Epoch 110/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.1174 - acc: 0.9550 - val_loss: 0.2644 - val_acc: 0.9100\n",
      "Epoch 111/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1144 - acc: 0.9562 - val_loss: 0.3311 - val_acc: 0.9070\n",
      "Epoch 112/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.1049 - acc: 0.9574 - val_loss: 0.2780 - val_acc: 0.9020\n",
      "Epoch 113/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1141 - acc: 0.9571 - val_loss: 0.2793 - val_acc: 0.9090\n",
      "Epoch 114/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.1136 - acc: 0.9567 - val_loss: 0.2688 - val_acc: 0.9090\n",
      "Epoch 115/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.1104 - acc: 0.9569 - val_loss: 0.3017 - val_acc: 0.9090\n",
      "Epoch 116/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.1024 - acc: 0.9613 - val_loss: 0.3466 - val_acc: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.1037 - acc: 0.9584 - val_loss: 0.2912 - val_acc: 0.9020\n",
      "Epoch 118/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.1036 - acc: 0.9613 - val_loss: 0.2569 - val_acc: 0.9020\n",
      "Epoch 119/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.1003 - acc: 0.9608 - val_loss: 0.3129 - val_acc: 0.9000\n",
      "Epoch 120/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.1018 - acc: 0.9597 - val_loss: 0.2947 - val_acc: 0.9050\n",
      "Epoch 121/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0975 - acc: 0.9629 - val_loss: 0.3060 - val_acc: 0.9040\n",
      "Epoch 122/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0982 - acc: 0.9625 - val_loss: 0.2641 - val_acc: 0.9110\n",
      "Epoch 123/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0889 - acc: 0.9666 - val_loss: 0.2769 - val_acc: 0.9090\n",
      "Epoch 124/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0891 - acc: 0.9648 - val_loss: 0.2780 - val_acc: 0.9170\n",
      "Epoch 125/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0863 - acc: 0.9672 - val_loss: 0.2717 - val_acc: 0.9090\n",
      "Epoch 126/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0940 - acc: 0.9641 - val_loss: 0.2887 - val_acc: 0.9110\n",
      "Epoch 127/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0860 - acc: 0.9666 - val_loss: 0.3191 - val_acc: 0.8990\n",
      "Epoch 128/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0869 - acc: 0.9662 - val_loss: 0.3140 - val_acc: 0.9170\n",
      "Epoch 129/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0870 - acc: 0.9671 - val_loss: 0.2999 - val_acc: 0.9130\n",
      "Epoch 130/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0810 - acc: 0.9684 - val_loss: 0.3386 - val_acc: 0.9050\n",
      "Epoch 131/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0808 - acc: 0.9712 - val_loss: 0.3290 - val_acc: 0.9020\n",
      "Epoch 132/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0833 - acc: 0.9698 - val_loss: 0.3304 - val_acc: 0.9180\n",
      "Epoch 133/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0778 - acc: 0.9713 - val_loss: 0.2706 - val_acc: 0.9080\n",
      "Epoch 134/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0847 - acc: 0.9689 - val_loss: 0.3391 - val_acc: 0.9140\n",
      "Epoch 135/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0766 - acc: 0.9721 - val_loss: 0.3221 - val_acc: 0.9100\n",
      "Epoch 136/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0778 - acc: 0.9720 - val_loss: 0.3464 - val_acc: 0.9140\n",
      "Epoch 137/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0821 - acc: 0.9708 - val_loss: 0.2858 - val_acc: 0.9180\n",
      "Epoch 138/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0738 - acc: 0.9736 - val_loss: 0.3367 - val_acc: 0.9170\n",
      "Epoch 139/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.3217 - val_acc: 0.9040\n",
      "Epoch 140/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0713 - acc: 0.9733 - val_loss: 0.3402 - val_acc: 0.9120\n",
      "Epoch 141/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0720 - acc: 0.9748 - val_loss: 0.3239 - val_acc: 0.9110\n",
      "Epoch 142/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0687 - acc: 0.9752 - val_loss: 0.3784 - val_acc: 0.9140\n",
      "Epoch 143/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0749 - acc: 0.9754 - val_loss: 0.3067 - val_acc: 0.9220\n",
      "Epoch 144/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0701 - acc: 0.9761 - val_loss: 0.3521 - val_acc: 0.9230\n",
      "Epoch 145/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0785 - acc: 0.9735 - val_loss: 0.2936 - val_acc: 0.9120\n",
      "Epoch 146/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0696 - acc: 0.9759 - val_loss: 0.3234 - val_acc: 0.9160\n",
      "Epoch 147/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0682 - acc: 0.9768 - val_loss: 0.3422 - val_acc: 0.9110\n",
      "Epoch 148/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0680 - acc: 0.9767 - val_loss: 0.3100 - val_acc: 0.9300\n",
      "Epoch 149/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0716 - acc: 0.9778 - val_loss: 0.2947 - val_acc: 0.9260\n",
      "Epoch 150/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0642 - acc: 0.9787 - val_loss: 0.3290 - val_acc: 0.9170\n",
      "Epoch 151/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0605 - acc: 0.9781 - val_loss: 0.3807 - val_acc: 0.9250\n",
      "Epoch 152/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0651 - acc: 0.9769 - val_loss: 0.3598 - val_acc: 0.9150\n",
      "Epoch 153/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0669 - acc: 0.9795 - val_loss: 0.3176 - val_acc: 0.9200\n",
      "Epoch 154/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0643 - acc: 0.9793 - val_loss: 0.3172 - val_acc: 0.9190\n",
      "Epoch 155/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0662 - acc: 0.9781 - val_loss: 0.3349 - val_acc: 0.9230\n",
      "Epoch 156/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0569 - acc: 0.9806 - val_loss: 0.3669 - val_acc: 0.9250\n",
      "Epoch 157/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.0596 - acc: 0.9793 - val_loss: 0.3250 - val_acc: 0.9170\n",
      "Epoch 158/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.0552 - acc: 0.9827 - val_loss: 0.4120 - val_acc: 0.9170\n",
      "Epoch 159/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0580 - acc: 0.9807 - val_loss: 0.3366 - val_acc: 0.9260\n",
      "Epoch 160/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0563 - acc: 0.9814 - val_loss: 0.3199 - val_acc: 0.9220\n",
      "Epoch 161/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0569 - acc: 0.9822 - val_loss: 0.3164 - val_acc: 0.9220\n",
      "Epoch 162/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0529 - acc: 0.9820 - val_loss: 0.3881 - val_acc: 0.9260\n",
      "Epoch 163/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0610 - acc: 0.9819 - val_loss: 0.3750 - val_acc: 0.9030\n",
      "Epoch 164/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0574 - acc: 0.9835 - val_loss: 0.3594 - val_acc: 0.9200\n",
      "Epoch 165/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0585 - acc: 0.9813 - val_loss: 0.3535 - val_acc: 0.9220\n",
      "Epoch 166/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0554 - acc: 0.9822 - val_loss: 0.4058 - val_acc: 0.9090\n",
      "Epoch 167/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0486 - acc: 0.9839 - val_loss: 0.3470 - val_acc: 0.9300\n",
      "Epoch 168/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0470 - acc: 0.9854 - val_loss: 0.3735 - val_acc: 0.9270\n",
      "Epoch 169/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0477 - acc: 0.9841 - val_loss: 0.4115 - val_acc: 0.9280\n",
      "Epoch 170/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0485 - acc: 0.9843 - val_loss: 0.3787 - val_acc: 0.9170\n",
      "Epoch 171/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0455 - acc: 0.9843 - val_loss: 0.3560 - val_acc: 0.9230\n",
      "Epoch 172/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0488 - acc: 0.9853 - val_loss: 0.3578 - val_acc: 0.9260\n",
      "Epoch 173/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0496 - acc: 0.9835 - val_loss: 0.3260 - val_acc: 0.9260\n",
      "Epoch 174/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0453 - acc: 0.9851 - val_loss: 0.4171 - val_acc: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0446 - acc: 0.9856 - val_loss: 0.4176 - val_acc: 0.9230\n",
      "Epoch 176/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0451 - acc: 0.9866 - val_loss: 0.3798 - val_acc: 0.9190\n",
      "Epoch 177/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0407 - acc: 0.9877 - val_loss: 0.3732 - val_acc: 0.9220\n",
      "Epoch 178/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0443 - acc: 0.9867 - val_loss: 0.3484 - val_acc: 0.9190\n",
      "Epoch 179/1000\n",
      "10000/10000 [==============================] - 4s 368us/step - loss: 0.0501 - acc: 0.9883 - val_loss: 0.3861 - val_acc: 0.9150\n",
      "Epoch 180/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0432 - acc: 0.9873 - val_loss: 0.3677 - val_acc: 0.9220\n",
      "Epoch 181/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0447 - acc: 0.9863 - val_loss: 0.4313 - val_acc: 0.9150\n",
      "Epoch 182/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0482 - acc: 0.9862 - val_loss: 0.4232 - val_acc: 0.9210\n",
      "Epoch 183/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0371 - acc: 0.9888 - val_loss: 0.4428 - val_acc: 0.9270\n",
      "Epoch 184/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0410 - acc: 0.9879 - val_loss: 0.3738 - val_acc: 0.9200\n",
      "Epoch 185/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0508 - acc: 0.9861 - val_loss: 0.4035 - val_acc: 0.9300\n",
      "Epoch 186/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0414 - acc: 0.9873 - val_loss: 0.3692 - val_acc: 0.9340\n",
      "Epoch 187/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0445 - acc: 0.9873 - val_loss: 0.3438 - val_acc: 0.9260\n",
      "Epoch 188/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0444 - acc: 0.9881 - val_loss: 0.3604 - val_acc: 0.9320\n",
      "Epoch 189/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0405 - acc: 0.9863 - val_loss: 0.3562 - val_acc: 0.9250\n",
      "Epoch 190/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0461 - acc: 0.9865 - val_loss: 0.3139 - val_acc: 0.9340\n",
      "Epoch 191/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0404 - acc: 0.9875 - val_loss: 0.3574 - val_acc: 0.9320\n",
      "Epoch 192/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0354 - acc: 0.9902 - val_loss: 0.3513 - val_acc: 0.9400\n",
      "Epoch 193/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0351 - acc: 0.9898 - val_loss: 0.4020 - val_acc: 0.9210\n",
      "Epoch 194/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0446 - acc: 0.9874 - val_loss: 0.3972 - val_acc: 0.9260\n",
      "Epoch 195/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0384 - acc: 0.9889 - val_loss: 0.3527 - val_acc: 0.9390\n",
      "Epoch 196/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0419 - acc: 0.9881 - val_loss: 0.3646 - val_acc: 0.9350\n",
      "Epoch 197/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0313 - acc: 0.9918 - val_loss: 0.4916 - val_acc: 0.9290\n",
      "Epoch 198/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0388 - acc: 0.9898 - val_loss: 0.3992 - val_acc: 0.9230\n",
      "Epoch 199/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0440 - acc: 0.9878 - val_loss: 0.4154 - val_acc: 0.9250\n",
      "Epoch 200/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0392 - acc: 0.9883 - val_loss: 0.4019 - val_acc: 0.9300\n",
      "Epoch 201/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0398 - acc: 0.9886 - val_loss: 0.4251 - val_acc: 0.9230\n",
      "Epoch 202/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0369 - acc: 0.9902 - val_loss: 0.3916 - val_acc: 0.9360\n",
      "Epoch 203/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0406 - acc: 0.9877 - val_loss: 0.4412 - val_acc: 0.9320\n",
      "Epoch 204/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0436 - acc: 0.9884 - val_loss: 0.4673 - val_acc: 0.9310\n",
      "Epoch 205/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0371 - acc: 0.9886 - val_loss: 0.4706 - val_acc: 0.9280\n",
      "Epoch 206/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0409 - acc: 0.9893 - val_loss: 0.4242 - val_acc: 0.9200\n",
      "Epoch 207/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0363 - acc: 0.9915 - val_loss: 0.4026 - val_acc: 0.9320\n",
      "Epoch 208/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0350 - acc: 0.9908 - val_loss: 0.4154 - val_acc: 0.9310\n",
      "Epoch 209/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0344 - acc: 0.9893 - val_loss: 0.3944 - val_acc: 0.9270\n",
      "Epoch 210/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0338 - acc: 0.9907 - val_loss: 0.4252 - val_acc: 0.9340\n",
      "Epoch 211/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0354 - acc: 0.9894 - val_loss: 0.4301 - val_acc: 0.9360\n",
      "Epoch 212/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0378 - acc: 0.9901 - val_loss: 0.4048 - val_acc: 0.9290\n",
      "Epoch 213/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0317 - acc: 0.9922 - val_loss: 0.4574 - val_acc: 0.9310\n",
      "Epoch 214/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0360 - acc: 0.9897 - val_loss: 0.4303 - val_acc: 0.9270\n",
      "Epoch 215/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0434 - acc: 0.9879 - val_loss: 0.3995 - val_acc: 0.9290\n",
      "Epoch 216/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0348 - acc: 0.9903 - val_loss: 0.4583 - val_acc: 0.9240\n",
      "Epoch 217/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0285 - acc: 0.9919 - val_loss: 0.4423 - val_acc: 0.9350\n",
      "Epoch 218/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0306 - acc: 0.9913 - val_loss: 0.4820 - val_acc: 0.9310\n",
      "Epoch 219/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0316 - acc: 0.9920 - val_loss: 0.4447 - val_acc: 0.9380\n",
      "Epoch 220/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0252 - acc: 0.9923 - val_loss: 0.4594 - val_acc: 0.9330\n",
      "Epoch 221/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.0359 - acc: 0.9904 - val_loss: 0.4321 - val_acc: 0.9320\n",
      "Epoch 222/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0352 - acc: 0.9899 - val_loss: 0.3823 - val_acc: 0.9330\n",
      "Epoch 223/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0296 - acc: 0.9922 - val_loss: 0.4389 - val_acc: 0.9310\n",
      "Epoch 224/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0335 - acc: 0.9909 - val_loss: 0.4402 - val_acc: 0.9390\n",
      "Epoch 225/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0303 - acc: 0.9914 - val_loss: 0.4040 - val_acc: 0.9340\n",
      "Epoch 226/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0337 - acc: 0.9908 - val_loss: 0.4285 - val_acc: 0.9340\n",
      "Epoch 227/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0296 - acc: 0.9918 - val_loss: 0.5482 - val_acc: 0.9270\n",
      "Epoch 228/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0327 - acc: 0.9919 - val_loss: 0.3946 - val_acc: 0.9350\n",
      "Epoch 229/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0261 - acc: 0.9916 - val_loss: 0.3976 - val_acc: 0.9350\n",
      "Epoch 230/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0313 - acc: 0.9914 - val_loss: 0.4579 - val_acc: 0.9320\n",
      "Epoch 231/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0288 - acc: 0.9919 - val_loss: 0.4325 - val_acc: 0.9380\n",
      "Epoch 232/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0317 - acc: 0.9916 - val_loss: 0.4518 - val_acc: 0.9300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0385 - acc: 0.9902 - val_loss: 0.4564 - val_acc: 0.9230\n",
      "Epoch 234/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0349 - acc: 0.9909 - val_loss: 0.4386 - val_acc: 0.9290\n",
      "Epoch 235/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0261 - acc: 0.9934 - val_loss: 0.4615 - val_acc: 0.9300\n",
      "Epoch 236/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0300 - acc: 0.9924 - val_loss: 0.4265 - val_acc: 0.9240\n",
      "Epoch 237/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0280 - acc: 0.9931 - val_loss: 0.4997 - val_acc: 0.9300\n",
      "Epoch 238/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0252 - acc: 0.9931 - val_loss: 0.4562 - val_acc: 0.9360\n",
      "Epoch 239/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0325 - acc: 0.9923 - val_loss: 0.4049 - val_acc: 0.9370\n",
      "Epoch 240/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0340 - acc: 0.9913 - val_loss: 0.4509 - val_acc: 0.9380\n",
      "Epoch 241/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0282 - acc: 0.9929 - val_loss: 0.4927 - val_acc: 0.9400\n",
      "Epoch 242/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0277 - acc: 0.9909 - val_loss: 0.4249 - val_acc: 0.9340\n",
      "Epoch 243/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0291 - acc: 0.9927 - val_loss: 0.4461 - val_acc: 0.9320\n",
      "Epoch 244/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0333 - acc: 0.9901 - val_loss: 0.4894 - val_acc: 0.9330\n",
      "Epoch 245/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0263 - acc: 0.9928 - val_loss: 0.4818 - val_acc: 0.9320\n",
      "Epoch 246/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0299 - acc: 0.9926 - val_loss: 0.4484 - val_acc: 0.9380\n",
      "Epoch 247/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0323 - acc: 0.9915 - val_loss: 0.4716 - val_acc: 0.9360\n",
      "Epoch 248/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0259 - acc: 0.9927 - val_loss: 0.4547 - val_acc: 0.9360\n",
      "Epoch 249/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0412 - acc: 0.9909 - val_loss: 0.4612 - val_acc: 0.9350\n",
      "Epoch 250/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0323 - acc: 0.9925 - val_loss: 0.4311 - val_acc: 0.9380\n",
      "Epoch 251/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0262 - acc: 0.9934 - val_loss: 0.4526 - val_acc: 0.9410\n",
      "Epoch 252/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0293 - acc: 0.9930 - val_loss: 0.4217 - val_acc: 0.9340\n",
      "Epoch 253/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0359 - acc: 0.9920 - val_loss: 0.4297 - val_acc: 0.9370\n",
      "Epoch 254/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0311 - acc: 0.9926 - val_loss: 0.4422 - val_acc: 0.9360\n",
      "Epoch 255/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0284 - acc: 0.9921 - val_loss: 0.4422 - val_acc: 0.9300\n",
      "Epoch 256/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0247 - acc: 0.9927 - val_loss: 0.4662 - val_acc: 0.9330\n",
      "Epoch 257/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0250 - acc: 0.9910 - val_loss: 0.4654 - val_acc: 0.9400\n",
      "Epoch 258/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0319 - acc: 0.9923 - val_loss: 0.4067 - val_acc: 0.9390\n",
      "Epoch 259/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0348 - acc: 0.9916 - val_loss: 0.3874 - val_acc: 0.9410\n",
      "Epoch 260/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0247 - acc: 0.9938 - val_loss: 0.4690 - val_acc: 0.9420\n",
      "Epoch 261/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0253 - acc: 0.9933 - val_loss: 0.4362 - val_acc: 0.9440\n",
      "Epoch 262/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0333 - acc: 0.9919 - val_loss: 0.4756 - val_acc: 0.9380\n",
      "Epoch 263/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0255 - acc: 0.9939 - val_loss: 0.4133 - val_acc: 0.9400\n",
      "Epoch 264/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0283 - acc: 0.9928 - val_loss: 0.4736 - val_acc: 0.9390\n",
      "Epoch 265/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0267 - acc: 0.9921 - val_loss: 0.4334 - val_acc: 0.9420\n",
      "Epoch 266/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0253 - acc: 0.9939 - val_loss: 0.3875 - val_acc: 0.9420\n",
      "Epoch 267/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0282 - acc: 0.9938 - val_loss: 0.4724 - val_acc: 0.9430\n",
      "Epoch 268/1000\n",
      "10000/10000 [==============================] - 4s 368us/step - loss: 0.0269 - acc: 0.9942 - val_loss: 0.4701 - val_acc: 0.9390\n",
      "Epoch 269/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0223 - acc: 0.9943 - val_loss: 0.4882 - val_acc: 0.9360\n",
      "Epoch 270/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0276 - acc: 0.9935 - val_loss: 0.3597 - val_acc: 0.9430\n",
      "Epoch 271/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0244 - acc: 0.9932 - val_loss: 0.4813 - val_acc: 0.9280\n",
      "Epoch 272/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0271 - acc: 0.9933 - val_loss: 0.4308 - val_acc: 0.9410\n",
      "Epoch 273/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0274 - acc: 0.9938 - val_loss: 0.4104 - val_acc: 0.9410\n",
      "Epoch 274/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0228 - acc: 0.9949 - val_loss: 0.4655 - val_acc: 0.9400\n",
      "Epoch 275/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0262 - acc: 0.9932 - val_loss: 0.4706 - val_acc: 0.9300\n",
      "Epoch 276/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0227 - acc: 0.9943 - val_loss: 0.4559 - val_acc: 0.9370\n",
      "Epoch 277/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0357 - acc: 0.9926 - val_loss: 0.4353 - val_acc: 0.9440\n",
      "Epoch 278/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0239 - acc: 0.9943 - val_loss: 0.4086 - val_acc: 0.9380\n",
      "Epoch 279/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0309 - acc: 0.9916 - val_loss: 0.4529 - val_acc: 0.9440\n",
      "Epoch 280/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0294 - acc: 0.9950 - val_loss: 0.3992 - val_acc: 0.9410\n",
      "Epoch 281/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0264 - acc: 0.9926 - val_loss: 0.4239 - val_acc: 0.9400\n",
      "Epoch 282/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0246 - acc: 0.9933 - val_loss: 0.3906 - val_acc: 0.9430\n",
      "Epoch 283/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0262 - acc: 0.9934 - val_loss: 0.4502 - val_acc: 0.9380\n",
      "Epoch 284/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0288 - acc: 0.9936 - val_loss: 0.4376 - val_acc: 0.9400\n",
      "Epoch 285/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0226 - acc: 0.9944 - val_loss: 0.4522 - val_acc: 0.9410\n",
      "Epoch 286/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0278 - acc: 0.9930 - val_loss: 0.4261 - val_acc: 0.9310\n",
      "Epoch 287/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0323 - acc: 0.9923 - val_loss: 0.4628 - val_acc: 0.9340\n",
      "Epoch 288/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0235 - acc: 0.9944 - val_loss: 0.4045 - val_acc: 0.9440\n",
      "Epoch 289/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0244 - acc: 0.9941 - val_loss: 0.4571 - val_acc: 0.9320\n",
      "Epoch 290/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0274 - acc: 0.9936 - val_loss: 0.4349 - val_acc: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0305 - acc: 0.9936 - val_loss: 0.4263 - val_acc: 0.9450\n",
      "Epoch 292/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.4890 - val_acc: 0.9440\n",
      "Epoch 293/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0276 - acc: 0.9940 - val_loss: 0.4586 - val_acc: 0.9430\n",
      "Epoch 294/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0283 - acc: 0.9929 - val_loss: 0.4574 - val_acc: 0.9420\n",
      "Epoch 295/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0260 - acc: 0.9928 - val_loss: 0.3888 - val_acc: 0.9400\n",
      "Epoch 296/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0258 - acc: 0.9933 - val_loss: 0.4241 - val_acc: 0.9400\n",
      "Epoch 297/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0271 - acc: 0.9930 - val_loss: 0.5185 - val_acc: 0.9320\n",
      "Epoch 298/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0271 - acc: 0.9931 - val_loss: 0.4413 - val_acc: 0.9370\n",
      "Epoch 299/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0224 - acc: 0.9954 - val_loss: 0.4563 - val_acc: 0.9460\n",
      "Epoch 300/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0280 - acc: 0.9938 - val_loss: 0.4192 - val_acc: 0.9420\n",
      "Epoch 301/1000\n",
      "10000/10000 [==============================] - 4s 368us/step - loss: 0.0212 - acc: 0.9944 - val_loss: 0.4129 - val_acc: 0.9440\n",
      "Epoch 302/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0310 - acc: 0.9938 - val_loss: 0.3847 - val_acc: 0.9380\n",
      "Epoch 303/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0253 - acc: 0.9938 - val_loss: 0.4360 - val_acc: 0.9370\n",
      "Epoch 304/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0259 - acc: 0.9942 - val_loss: 0.4475 - val_acc: 0.9380\n",
      "Epoch 305/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0267 - acc: 0.9938 - val_loss: 0.4223 - val_acc: 0.9360\n",
      "Epoch 306/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0304 - acc: 0.9936 - val_loss: 0.4373 - val_acc: 0.9400\n",
      "Epoch 307/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0252 - acc: 0.9941 - val_loss: 0.4826 - val_acc: 0.9310\n",
      "Epoch 308/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0227 - acc: 0.9940 - val_loss: 0.4920 - val_acc: 0.9370\n",
      "Epoch 309/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0237 - acc: 0.9937 - val_loss: 0.4718 - val_acc: 0.9380\n",
      "Epoch 310/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0210 - acc: 0.9951 - val_loss: 0.4619 - val_acc: 0.9320\n",
      "Epoch 311/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0255 - acc: 0.9927 - val_loss: 0.4119 - val_acc: 0.9350\n",
      "Epoch 312/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0281 - acc: 0.9943 - val_loss: 0.4832 - val_acc: 0.9410\n",
      "Epoch 313/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0305 - acc: 0.9943 - val_loss: 0.4695 - val_acc: 0.9430\n",
      "Epoch 314/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0211 - acc: 0.9950 - val_loss: 0.4359 - val_acc: 0.9380\n",
      "Epoch 315/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0230 - acc: 0.9950 - val_loss: 0.4430 - val_acc: 0.9420\n",
      "Epoch 316/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0233 - acc: 0.9952 - val_loss: 0.4297 - val_acc: 0.9390\n",
      "Epoch 317/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0232 - acc: 0.9938 - val_loss: 0.4474 - val_acc: 0.9390\n",
      "Epoch 318/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0178 - acc: 0.9951 - val_loss: 0.4694 - val_acc: 0.9460\n",
      "Epoch 319/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0241 - acc: 0.9942 - val_loss: 0.4700 - val_acc: 0.9470\n",
      "Epoch 320/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0280 - acc: 0.9946 - val_loss: 0.4952 - val_acc: 0.9430\n",
      "Epoch 321/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0194 - acc: 0.9948 - val_loss: 0.5126 - val_acc: 0.9380\n",
      "Epoch 322/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0247 - acc: 0.9941 - val_loss: 0.3913 - val_acc: 0.9370\n",
      "Epoch 323/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0303 - acc: 0.9932 - val_loss: 0.4163 - val_acc: 0.9450\n",
      "Epoch 324/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0273 - acc: 0.9936 - val_loss: 0.4133 - val_acc: 0.9390\n",
      "Epoch 325/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0232 - acc: 0.9947 - val_loss: 0.4866 - val_acc: 0.9340\n",
      "Epoch 326/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0253 - acc: 0.9950 - val_loss: 0.4441 - val_acc: 0.9440\n",
      "Epoch 327/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0367 - acc: 0.9928 - val_loss: 0.4398 - val_acc: 0.9340\n",
      "Epoch 328/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0258 - acc: 0.9941 - val_loss: 0.4199 - val_acc: 0.9370\n",
      "Epoch 329/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0265 - acc: 0.9940 - val_loss: 0.4158 - val_acc: 0.9390\n",
      "Epoch 330/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0234 - acc: 0.9937 - val_loss: 0.4578 - val_acc: 0.9400\n",
      "Epoch 331/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0252 - acc: 0.9937 - val_loss: 0.4223 - val_acc: 0.9400\n",
      "Epoch 332/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0316 - acc: 0.9936 - val_loss: 0.4345 - val_acc: 0.9320\n",
      "Epoch 333/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0317 - acc: 0.9942 - val_loss: 0.4697 - val_acc: 0.9420\n",
      "Epoch 334/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0223 - acc: 0.9951 - val_loss: 0.4282 - val_acc: 0.9380\n",
      "Epoch 335/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0198 - acc: 0.9942 - val_loss: 0.4261 - val_acc: 0.9410\n",
      "Epoch 336/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0202 - acc: 0.9951 - val_loss: 0.4804 - val_acc: 0.9390\n",
      "Epoch 337/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0208 - acc: 0.9944 - val_loss: 0.4124 - val_acc: 0.9410\n",
      "Epoch 338/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0333 - acc: 0.9928 - val_loss: 0.4425 - val_acc: 0.9400\n",
      "Epoch 339/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0239 - acc: 0.9935 - val_loss: 0.3757 - val_acc: 0.9370\n",
      "Epoch 340/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0218 - acc: 0.9945 - val_loss: 0.4027 - val_acc: 0.9440\n",
      "Epoch 341/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0254 - acc: 0.9943 - val_loss: 0.4603 - val_acc: 0.9450\n",
      "Epoch 342/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0212 - acc: 0.9954 - val_loss: 0.4198 - val_acc: 0.9480\n",
      "Epoch 343/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0296 - acc: 0.9941 - val_loss: 0.3437 - val_acc: 0.9420\n",
      "Epoch 344/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0238 - acc: 0.9934 - val_loss: 0.4519 - val_acc: 0.9400\n",
      "Epoch 345/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0235 - acc: 0.9945 - val_loss: 0.4697 - val_acc: 0.9440\n",
      "Epoch 346/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0253 - acc: 0.9946 - val_loss: 0.4680 - val_acc: 0.9390\n",
      "Epoch 347/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0272 - acc: 0.9946 - val_loss: 0.4598 - val_acc: 0.9320\n",
      "Epoch 348/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0250 - acc: 0.9933 - val_loss: 0.4162 - val_acc: 0.9360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0231 - acc: 0.9947 - val_loss: 0.3940 - val_acc: 0.9450\n",
      "Epoch 350/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0260 - acc: 0.9945 - val_loss: 0.4491 - val_acc: 0.9460\n",
      "Epoch 351/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0334 - acc: 0.9934 - val_loss: 0.3868 - val_acc: 0.9340\n",
      "Epoch 352/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0240 - acc: 0.9939 - val_loss: 0.4257 - val_acc: 0.9480\n",
      "Epoch 353/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0308 - acc: 0.9936 - val_loss: 0.3655 - val_acc: 0.9360\n",
      "Epoch 354/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0245 - acc: 0.9941 - val_loss: 0.3727 - val_acc: 0.9430\n",
      "Epoch 355/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0191 - acc: 0.9951 - val_loss: 0.4141 - val_acc: 0.9480\n",
      "Epoch 356/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0283 - acc: 0.9944 - val_loss: 0.4294 - val_acc: 0.9340\n",
      "Epoch 357/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0287 - acc: 0.9940 - val_loss: 0.3451 - val_acc: 0.9480\n",
      "Epoch 358/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0297 - acc: 0.9932 - val_loss: 0.3488 - val_acc: 0.9440\n",
      "Epoch 359/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0210 - acc: 0.9947 - val_loss: 0.3768 - val_acc: 0.9510\n",
      "Epoch 360/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0258 - acc: 0.9947 - val_loss: 0.3507 - val_acc: 0.9460\n",
      "Epoch 361/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0227 - acc: 0.9948 - val_loss: 0.3819 - val_acc: 0.9490\n",
      "Epoch 362/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0246 - acc: 0.9949 - val_loss: 0.4323 - val_acc: 0.9480\n",
      "Epoch 363/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0270 - acc: 0.9941 - val_loss: 0.3586 - val_acc: 0.9480\n",
      "Epoch 364/1000\n",
      "10000/10000 [==============================] - 4s 368us/step - loss: 0.0339 - acc: 0.9938 - val_loss: 0.3686 - val_acc: 0.9430\n",
      "Epoch 365/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0263 - acc: 0.9948 - val_loss: 0.4102 - val_acc: 0.9450\n",
      "Epoch 366/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0191 - acc: 0.9955 - val_loss: 0.4143 - val_acc: 0.9470\n",
      "Epoch 367/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0254 - acc: 0.9932 - val_loss: 0.3728 - val_acc: 0.9510\n",
      "Epoch 368/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0278 - acc: 0.9946 - val_loss: 0.3809 - val_acc: 0.9530\n",
      "Epoch 369/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0285 - acc: 0.9939 - val_loss: 0.4221 - val_acc: 0.9440\n",
      "Epoch 370/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0307 - acc: 0.9940 - val_loss: 0.3647 - val_acc: 0.9520\n",
      "Epoch 371/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0244 - acc: 0.9942 - val_loss: 0.3796 - val_acc: 0.9430\n",
      "Epoch 372/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0258 - acc: 0.9940 - val_loss: 0.4133 - val_acc: 0.9530\n",
      "Epoch 373/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0242 - acc: 0.9945 - val_loss: 0.3772 - val_acc: 0.9460\n",
      "Epoch 374/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0218 - acc: 0.9946 - val_loss: 0.4442 - val_acc: 0.9440\n",
      "Epoch 375/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0252 - acc: 0.9942 - val_loss: 0.4633 - val_acc: 0.9470\n",
      "Epoch 376/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0285 - acc: 0.9936 - val_loss: 0.3453 - val_acc: 0.9450\n",
      "Epoch 377/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0188 - acc: 0.9954 - val_loss: 0.4014 - val_acc: 0.9460\n",
      "Epoch 378/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0212 - acc: 0.9949 - val_loss: 0.4295 - val_acc: 0.9500\n",
      "Epoch 379/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0200 - acc: 0.9963 - val_loss: 0.4290 - val_acc: 0.9510\n",
      "Epoch 380/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0204 - acc: 0.9955 - val_loss: 0.4093 - val_acc: 0.9480\n",
      "Epoch 381/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0213 - acc: 0.9959 - val_loss: 0.4572 - val_acc: 0.9400\n",
      "Epoch 382/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0223 - acc: 0.9950 - val_loss: 0.4646 - val_acc: 0.9410\n",
      "Epoch 383/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0265 - acc: 0.9932 - val_loss: 0.4327 - val_acc: 0.9400\n",
      "Epoch 384/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0273 - acc: 0.9950 - val_loss: 0.4232 - val_acc: 0.9500\n",
      "Epoch 385/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0306 - acc: 0.9939 - val_loss: 0.3673 - val_acc: 0.9480\n",
      "Epoch 386/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0350 - acc: 0.9938 - val_loss: 0.3701 - val_acc: 0.9460\n",
      "Epoch 387/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0374 - acc: 0.9934 - val_loss: 0.4128 - val_acc: 0.9440\n",
      "Epoch 388/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0242 - acc: 0.9937 - val_loss: 0.4100 - val_acc: 0.9450\n",
      "Epoch 389/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0268 - acc: 0.9938 - val_loss: 0.3513 - val_acc: 0.9490\n",
      "Epoch 390/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0249 - acc: 0.9946 - val_loss: 0.4143 - val_acc: 0.9440\n",
      "Epoch 391/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0254 - acc: 0.9951 - val_loss: 0.4385 - val_acc: 0.9410\n",
      "Epoch 392/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0275 - acc: 0.9944 - val_loss: 0.3681 - val_acc: 0.9430\n",
      "Epoch 393/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0270 - acc: 0.9944 - val_loss: 0.3907 - val_acc: 0.9490\n",
      "Epoch 394/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0278 - acc: 0.9957 - val_loss: 0.4512 - val_acc: 0.9490\n",
      "Epoch 395/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0294 - acc: 0.9941 - val_loss: 0.4268 - val_acc: 0.9480\n",
      "Epoch 396/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0266 - acc: 0.9953 - val_loss: 0.4357 - val_acc: 0.9460\n",
      "Epoch 397/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0312 - acc: 0.9947 - val_loss: 0.3640 - val_acc: 0.9450\n",
      "Epoch 398/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0307 - acc: 0.9944 - val_loss: 0.3563 - val_acc: 0.9520\n",
      "Epoch 399/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0343 - acc: 0.9936 - val_loss: 0.3264 - val_acc: 0.9470\n",
      "Epoch 400/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0250 - acc: 0.9946 - val_loss: 0.3781 - val_acc: 0.9480\n",
      "Epoch 401/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0275 - acc: 0.9944 - val_loss: 0.4238 - val_acc: 0.9440\n",
      "Epoch 402/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0321 - acc: 0.9922 - val_loss: 0.4157 - val_acc: 0.9460\n",
      "Epoch 403/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0237 - acc: 0.9938 - val_loss: 0.4249 - val_acc: 0.9470\n",
      "Epoch 404/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0293 - acc: 0.9939 - val_loss: 0.3994 - val_acc: 0.9510\n",
      "Epoch 405/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0338 - acc: 0.9928 - val_loss: 0.3543 - val_acc: 0.9470\n",
      "Epoch 406/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0287 - acc: 0.9945 - val_loss: 0.4014 - val_acc: 0.9490\n",
      "Epoch 407/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0252 - acc: 0.9937 - val_loss: 0.3868 - val_acc: 0.9490\n",
      "Epoch 408/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0220 - acc: 0.9958 - val_loss: 0.4067 - val_acc: 0.9500\n",
      "Epoch 409/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0273 - acc: 0.9934 - val_loss: 0.3969 - val_acc: 0.9500\n",
      "Epoch 410/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0352 - acc: 0.9933 - val_loss: 0.4128 - val_acc: 0.9490\n",
      "Epoch 411/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.0281 - acc: 0.9939 - val_loss: 0.4150 - val_acc: 0.9520\n",
      "Epoch 412/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0322 - acc: 0.9947 - val_loss: 0.3472 - val_acc: 0.9540\n",
      "Epoch 413/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.4513 - val_acc: 0.9480\n",
      "Epoch 414/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0195 - acc: 0.9954 - val_loss: 0.3677 - val_acc: 0.9450\n",
      "Epoch 415/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0251 - acc: 0.9945 - val_loss: 0.4013 - val_acc: 0.9480\n",
      "Epoch 416/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0208 - acc: 0.9958 - val_loss: 0.4479 - val_acc: 0.9490\n",
      "Epoch 417/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0181 - acc: 0.9958 - val_loss: 0.4818 - val_acc: 0.9430\n",
      "Epoch 418/1000\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.0270 - acc: 0.9950 - val_loss: 0.4693 - val_acc: 0.9440\n",
      "Epoch 419/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0207 - acc: 0.9949 - val_loss: 0.4100 - val_acc: 0.9560\n",
      "Epoch 420/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0298 - acc: 0.9942 - val_loss: 0.3749 - val_acc: 0.9450\n",
      "Epoch 421/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0295 - acc: 0.9943 - val_loss: 0.3519 - val_acc: 0.9520\n",
      "Epoch 422/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0338 - acc: 0.9927 - val_loss: 0.3536 - val_acc: 0.9530\n",
      "Epoch 423/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0303 - acc: 0.9926 - val_loss: 0.3879 - val_acc: 0.9450\n",
      "Epoch 424/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.0304 - acc: 0.9937 - val_loss: 0.3765 - val_acc: 0.9480\n",
      "Epoch 425/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0247 - acc: 0.9944 - val_loss: 0.4292 - val_acc: 0.9450\n",
      "Epoch 426/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0258 - acc: 0.9948 - val_loss: 0.4340 - val_acc: 0.9470\n",
      "Epoch 427/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0232 - acc: 0.9947 - val_loss: 0.4212 - val_acc: 0.9450\n",
      "Epoch 428/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0345 - acc: 0.9923 - val_loss: 0.4442 - val_acc: 0.9410\n",
      "Epoch 429/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0238 - acc: 0.9946 - val_loss: 0.4253 - val_acc: 0.9490\n",
      "Epoch 430/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0214 - acc: 0.9945 - val_loss: 0.4162 - val_acc: 0.9410\n",
      "Epoch 431/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0233 - acc: 0.9955 - val_loss: 0.4067 - val_acc: 0.9480\n",
      "Epoch 432/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0269 - acc: 0.9944 - val_loss: 0.4347 - val_acc: 0.9480\n",
      "Epoch 433/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0248 - acc: 0.9948 - val_loss: 0.4271 - val_acc: 0.9430\n",
      "Epoch 434/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0262 - acc: 0.9947 - val_loss: 0.3963 - val_acc: 0.9480\n",
      "Epoch 435/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0294 - acc: 0.9950 - val_loss: 0.3970 - val_acc: 0.9440\n",
      "Epoch 436/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0328 - acc: 0.9952 - val_loss: 0.3630 - val_acc: 0.9520\n",
      "Epoch 437/1000\n",
      "10000/10000 [==============================] - 4s 369us/step - loss: 0.0173 - acc: 0.9956 - val_loss: 0.3980 - val_acc: 0.9540\n",
      "Epoch 438/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0232 - acc: 0.9954 - val_loss: 0.3919 - val_acc: 0.9500\n",
      "Epoch 439/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0223 - acc: 0.9956 - val_loss: 0.4261 - val_acc: 0.9470\n",
      "Epoch 440/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0239 - acc: 0.9944 - val_loss: 0.4824 - val_acc: 0.9490\n",
      "Epoch 441/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0289 - acc: 0.9953 - val_loss: 0.4389 - val_acc: 0.9450\n",
      "Epoch 442/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0293 - acc: 0.9944 - val_loss: 0.4035 - val_acc: 0.9490\n",
      "Epoch 443/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0261 - acc: 0.9948 - val_loss: 0.4530 - val_acc: 0.9450\n",
      "Epoch 444/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0255 - acc: 0.9957 - val_loss: 0.3959 - val_acc: 0.9520\n",
      "Epoch 445/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0290 - acc: 0.9928 - val_loss: 0.3336 - val_acc: 0.9510\n",
      "Epoch 446/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0250 - acc: 0.9951 - val_loss: 0.4017 - val_acc: 0.9340\n",
      "Epoch 447/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0257 - acc: 0.9943 - val_loss: 0.3510 - val_acc: 0.9490\n",
      "Epoch 448/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0232 - acc: 0.9954 - val_loss: 0.3549 - val_acc: 0.9500\n",
      "Epoch 449/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0326 - acc: 0.9943 - val_loss: 0.3862 - val_acc: 0.9480\n",
      "Epoch 450/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0250 - acc: 0.9952 - val_loss: 0.4413 - val_acc: 0.9410\n",
      "Epoch 451/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0248 - acc: 0.9949 - val_loss: 0.4158 - val_acc: 0.9460\n",
      "Epoch 452/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0251 - acc: 0.9952 - val_loss: 0.3390 - val_acc: 0.9470\n",
      "Epoch 453/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0279 - acc: 0.9943 - val_loss: 0.3738 - val_acc: 0.9490\n",
      "Epoch 454/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0249 - acc: 0.9959 - val_loss: 0.4323 - val_acc: 0.9390\n",
      "Epoch 455/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0326 - acc: 0.9931 - val_loss: 0.3833 - val_acc: 0.9510\n",
      "Epoch 456/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0191 - acc: 0.9960 - val_loss: 0.3818 - val_acc: 0.9500\n",
      "Epoch 457/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0226 - acc: 0.9946 - val_loss: 0.3637 - val_acc: 0.9490\n",
      "Epoch 458/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0367 - acc: 0.9932 - val_loss: 0.3677 - val_acc: 0.9530\n",
      "Epoch 459/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.0300 - acc: 0.9943 - val_loss: 0.3331 - val_acc: 0.9530\n",
      "Epoch 460/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0301 - acc: 0.9944 - val_loss: 0.3893 - val_acc: 0.9490\n",
      "Epoch 461/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.0289 - acc: 0.9953 - val_loss: 0.4275 - val_acc: 0.9380\n",
      "Epoch 462/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0209 - acc: 0.9959 - val_loss: 0.3987 - val_acc: 0.9520\n",
      "Epoch 463/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0245 - acc: 0.9954 - val_loss: 0.4951 - val_acc: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0278 - acc: 0.9945 - val_loss: 0.4224 - val_acc: 0.9560\n",
      "Epoch 465/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0296 - acc: 0.9947 - val_loss: 0.3093 - val_acc: 0.9460\n",
      "Epoch 466/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0333 - acc: 0.9944 - val_loss: 0.3222 - val_acc: 0.9490\n",
      "Epoch 467/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0290 - acc: 0.9941 - val_loss: 0.3857 - val_acc: 0.9530\n",
      "Epoch 468/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0358 - acc: 0.9937 - val_loss: 0.3638 - val_acc: 0.9440\n",
      "Epoch 469/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0264 - acc: 0.9953 - val_loss: 0.3679 - val_acc: 0.9450\n",
      "Epoch 470/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0306 - acc: 0.9948 - val_loss: 0.3887 - val_acc: 0.9440\n",
      "Epoch 471/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0297 - acc: 0.9954 - val_loss: 0.4367 - val_acc: 0.9420\n",
      "Epoch 472/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0398 - acc: 0.9931 - val_loss: 0.3278 - val_acc: 0.9450\n",
      "Epoch 473/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0395 - acc: 0.9937 - val_loss: 0.4222 - val_acc: 0.9430\n",
      "Epoch 474/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0212 - acc: 0.9951 - val_loss: 0.4316 - val_acc: 0.9430\n",
      "Epoch 475/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0270 - acc: 0.9947 - val_loss: 0.3386 - val_acc: 0.9560\n",
      "Epoch 476/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0297 - acc: 0.9951 - val_loss: 0.3145 - val_acc: 0.9550\n",
      "Epoch 477/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0301 - acc: 0.9935 - val_loss: 0.3379 - val_acc: 0.9570\n",
      "Epoch 478/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0209 - acc: 0.9955 - val_loss: 0.3605 - val_acc: 0.9550\n",
      "Epoch 479/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0289 - acc: 0.9942 - val_loss: 0.3419 - val_acc: 0.9540\n",
      "Epoch 480/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0288 - acc: 0.9942 - val_loss: 0.3822 - val_acc: 0.9460\n",
      "Epoch 481/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0300 - acc: 0.9945 - val_loss: 0.3900 - val_acc: 0.9500\n",
      "Epoch 482/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0269 - acc: 0.9946 - val_loss: 0.3866 - val_acc: 0.9460\n",
      "Epoch 483/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0272 - acc: 0.9939 - val_loss: 0.3226 - val_acc: 0.9570\n",
      "Epoch 484/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0266 - acc: 0.9952 - val_loss: 0.3667 - val_acc: 0.9520\n",
      "Epoch 485/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0302 - acc: 0.9935 - val_loss: 0.3368 - val_acc: 0.9520\n",
      "Epoch 486/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0335 - acc: 0.9938 - val_loss: 0.3576 - val_acc: 0.9520\n",
      "Epoch 487/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0217 - acc: 0.9945 - val_loss: 0.3550 - val_acc: 0.9530\n",
      "Epoch 488/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0257 - acc: 0.9941 - val_loss: 0.3754 - val_acc: 0.9490\n",
      "Epoch 489/1000\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.0286 - acc: 0.9948 - val_loss: 0.3546 - val_acc: 0.9510\n",
      "Epoch 490/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0215 - acc: 0.9948 - val_loss: 0.3510 - val_acc: 0.9510\n",
      "Epoch 491/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0320 - acc: 0.9937 - val_loss: 0.3469 - val_acc: 0.9500\n",
      "Epoch 492/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0383 - acc: 0.9930 - val_loss: 0.3705 - val_acc: 0.9520\n",
      "Epoch 493/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0298 - acc: 0.9934 - val_loss: 0.4167 - val_acc: 0.9510\n",
      "Epoch 494/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0324 - acc: 0.9941 - val_loss: 0.3765 - val_acc: 0.9540\n",
      "Epoch 495/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0397 - acc: 0.9929 - val_loss: 0.3342 - val_acc: 0.9570\n",
      "Epoch 496/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0211 - acc: 0.9948 - val_loss: 0.4062 - val_acc: 0.9470\n",
      "Epoch 497/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0294 - acc: 0.9946 - val_loss: 0.3922 - val_acc: 0.9460\n",
      "Epoch 498/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0289 - acc: 0.9943 - val_loss: 0.3734 - val_acc: 0.9520\n",
      "Epoch 499/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0358 - acc: 0.9927 - val_loss: 0.3888 - val_acc: 0.9470\n",
      "Epoch 500/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0294 - acc: 0.9951 - val_loss: 0.3757 - val_acc: 0.9480\n",
      "Epoch 501/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0315 - acc: 0.9953 - val_loss: 0.3923 - val_acc: 0.9540\n",
      "Epoch 502/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.0274 - acc: 0.9952 - val_loss: 0.4012 - val_acc: 0.9400\n",
      "Epoch 503/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0307 - acc: 0.9945 - val_loss: 0.4135 - val_acc: 0.9490\n",
      "Epoch 504/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0324 - acc: 0.9943 - val_loss: 0.4014 - val_acc: 0.9470\n",
      "Epoch 505/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0280 - acc: 0.9941 - val_loss: 0.3392 - val_acc: 0.9510\n",
      "Epoch 506/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0205 - acc: 0.9953 - val_loss: 0.4689 - val_acc: 0.9370\n",
      "Epoch 507/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0260 - acc: 0.9955 - val_loss: 0.4030 - val_acc: 0.9490\n",
      "Epoch 508/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0364 - acc: 0.9942 - val_loss: 0.3984 - val_acc: 0.9470\n",
      "Epoch 509/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0309 - acc: 0.9947 - val_loss: 0.3423 - val_acc: 0.9570\n",
      "Epoch 510/1000\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.0359 - acc: 0.9915 - val_loss: 0.3707 - val_acc: 0.9470\n",
      "Epoch 511/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0303 - acc: 0.9928 - val_loss: 0.3156 - val_acc: 0.9520\n",
      "Epoch 512/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0269 - acc: 0.9952 - val_loss: 0.3867 - val_acc: 0.9570\n",
      "Epoch 513/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0301 - acc: 0.9942 - val_loss: 0.3404 - val_acc: 0.9500\n",
      "Epoch 514/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0331 - acc: 0.9943 - val_loss: 0.3581 - val_acc: 0.9510\n",
      "Epoch 515/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0295 - acc: 0.9944 - val_loss: 0.3096 - val_acc: 0.9600\n",
      "Epoch 516/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0247 - acc: 0.9951 - val_loss: 0.3980 - val_acc: 0.9550\n",
      "Epoch 517/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0343 - acc: 0.9938 - val_loss: 0.3742 - val_acc: 0.9470\n",
      "Epoch 518/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0374 - acc: 0.9942 - val_loss: 0.3973 - val_acc: 0.9490\n",
      "Epoch 519/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0310 - acc: 0.9946 - val_loss: 0.3890 - val_acc: 0.9470\n",
      "Epoch 520/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0323 - acc: 0.9948 - val_loss: 0.3669 - val_acc: 0.9520\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0330 - acc: 0.9934 - val_loss: 0.4492 - val_acc: 0.9530\n",
      "Epoch 522/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0339 - acc: 0.9943 - val_loss: 0.3631 - val_acc: 0.9490\n",
      "Epoch 523/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0370 - acc: 0.9931 - val_loss: 0.3209 - val_acc: 0.9520\n",
      "Epoch 524/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0299 - acc: 0.9942 - val_loss: 0.3708 - val_acc: 0.9440\n",
      "Epoch 525/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0229 - acc: 0.9958 - val_loss: 0.3675 - val_acc: 0.9490\n",
      "Epoch 526/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0254 - acc: 0.9945 - val_loss: 0.3417 - val_acc: 0.9600\n",
      "Epoch 527/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0295 - acc: 0.9943 - val_loss: 0.4078 - val_acc: 0.9470\n",
      "Epoch 528/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0341 - acc: 0.9930 - val_loss: 0.3164 - val_acc: 0.9480\n",
      "Epoch 529/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0273 - acc: 0.9949 - val_loss: 0.3947 - val_acc: 0.9470\n",
      "Epoch 530/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0288 - acc: 0.9947 - val_loss: 0.3644 - val_acc: 0.9490\n",
      "Epoch 531/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0264 - acc: 0.9932 - val_loss: 0.3335 - val_acc: 0.9540\n",
      "Epoch 532/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0329 - acc: 0.9937 - val_loss: 0.3679 - val_acc: 0.9540\n",
      "Epoch 533/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0283 - acc: 0.9939 - val_loss: 0.4062 - val_acc: 0.9550\n",
      "Epoch 534/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0367 - acc: 0.9947 - val_loss: 0.3933 - val_acc: 0.9510\n",
      "Epoch 535/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0296 - acc: 0.9941 - val_loss: 0.3042 - val_acc: 0.9530\n",
      "Epoch 536/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0300 - acc: 0.9943 - val_loss: 0.3687 - val_acc: 0.9500\n",
      "Epoch 537/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0300 - acc: 0.9946 - val_loss: 0.3419 - val_acc: 0.9530\n",
      "Epoch 538/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0308 - acc: 0.9948 - val_loss: 0.3316 - val_acc: 0.9550\n",
      "Epoch 539/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0207 - acc: 0.9964 - val_loss: 0.3834 - val_acc: 0.9500\n",
      "Epoch 540/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0306 - acc: 0.9948 - val_loss: 0.4205 - val_acc: 0.9500\n",
      "Epoch 541/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0278 - acc: 0.9948 - val_loss: 0.3656 - val_acc: 0.9480\n",
      "Epoch 542/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0375 - acc: 0.9929 - val_loss: 0.4915 - val_acc: 0.9470\n",
      "Epoch 543/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0264 - acc: 0.9952 - val_loss: 0.4179 - val_acc: 0.9550\n",
      "Epoch 544/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0286 - acc: 0.9937 - val_loss: 0.3834 - val_acc: 0.9470\n",
      "Epoch 545/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0233 - acc: 0.9948 - val_loss: 0.3534 - val_acc: 0.9570\n",
      "Epoch 546/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0310 - acc: 0.9937 - val_loss: 0.3542 - val_acc: 0.9540\n",
      "Epoch 547/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0241 - acc: 0.9956 - val_loss: 0.4027 - val_acc: 0.9520\n",
      "Epoch 548/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0179 - acc: 0.9964 - val_loss: 0.3381 - val_acc: 0.9520\n",
      "Epoch 549/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0254 - acc: 0.9956 - val_loss: 0.3457 - val_acc: 0.9560\n",
      "Epoch 550/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0315 - acc: 0.9944 - val_loss: 0.3485 - val_acc: 0.9500\n",
      "Epoch 551/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0313 - acc: 0.9945 - val_loss: 0.3722 - val_acc: 0.9510\n",
      "Epoch 552/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0295 - acc: 0.9946 - val_loss: 0.4089 - val_acc: 0.9460\n",
      "Epoch 553/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0355 - acc: 0.9931 - val_loss: 0.3413 - val_acc: 0.9470\n",
      "Epoch 554/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0264 - acc: 0.9941 - val_loss: 0.4303 - val_acc: 0.9400\n",
      "Epoch 555/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0371 - acc: 0.9939 - val_loss: 0.3737 - val_acc: 0.9480\n",
      "Epoch 556/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0291 - acc: 0.9951 - val_loss: 0.3694 - val_acc: 0.9510\n",
      "Epoch 557/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0269 - acc: 0.9945 - val_loss: 0.3726 - val_acc: 0.9490\n",
      "Epoch 558/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0256 - acc: 0.9956 - val_loss: 0.3639 - val_acc: 0.9530\n",
      "Epoch 559/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0259 - acc: 0.9947 - val_loss: 0.3812 - val_acc: 0.9610\n",
      "Epoch 560/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0402 - acc: 0.9939 - val_loss: 0.3674 - val_acc: 0.9530\n",
      "Epoch 561/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0299 - acc: 0.9945 - val_loss: 0.3705 - val_acc: 0.9510\n",
      "Epoch 562/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0234 - acc: 0.9951 - val_loss: 0.3331 - val_acc: 0.9620\n",
      "Epoch 563/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0389 - acc: 0.9933 - val_loss: 0.3598 - val_acc: 0.9540\n",
      "Epoch 564/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0309 - acc: 0.9942 - val_loss: 0.3577 - val_acc: 0.9480\n",
      "Epoch 565/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0261 - acc: 0.9953 - val_loss: 0.3434 - val_acc: 0.9550\n",
      "Epoch 566/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0222 - acc: 0.9955 - val_loss: 0.3343 - val_acc: 0.9510\n",
      "Epoch 567/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0292 - acc: 0.9946 - val_loss: 0.3589 - val_acc: 0.9530\n",
      "Epoch 568/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0216 - acc: 0.9953 - val_loss: 0.3845 - val_acc: 0.9540\n",
      "Epoch 569/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0324 - acc: 0.9934 - val_loss: 0.3224 - val_acc: 0.9500\n",
      "Epoch 570/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0233 - acc: 0.9953 - val_loss: 0.3342 - val_acc: 0.9530\n",
      "Epoch 571/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0282 - acc: 0.9942 - val_loss: 0.2873 - val_acc: 0.9510\n",
      "Epoch 572/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0266 - acc: 0.9952 - val_loss: 0.3767 - val_acc: 0.9590\n",
      "Epoch 573/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0290 - acc: 0.9943 - val_loss: 0.3838 - val_acc: 0.9490\n",
      "Epoch 574/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0322 - acc: 0.9939 - val_loss: 0.3195 - val_acc: 0.9590\n",
      "Epoch 575/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0313 - acc: 0.9941 - val_loss: 0.3681 - val_acc: 0.9580\n",
      "Epoch 576/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0330 - acc: 0.9934 - val_loss: 0.3625 - val_acc: 0.9550\n",
      "Epoch 577/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0248 - acc: 0.9941 - val_loss: 0.3732 - val_acc: 0.9520\n",
      "Epoch 578/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0348 - acc: 0.9946 - val_loss: 0.3314 - val_acc: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0281 - acc: 0.9958 - val_loss: 0.3433 - val_acc: 0.9580\n",
      "Epoch 580/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0293 - acc: 0.9935 - val_loss: 0.3467 - val_acc: 0.9540\n",
      "Epoch 581/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0227 - acc: 0.9951 - val_loss: 0.3603 - val_acc: 0.9520\n",
      "Epoch 582/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0238 - acc: 0.9950 - val_loss: 0.4450 - val_acc: 0.9530\n",
      "Epoch 583/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0376 - acc: 0.9944 - val_loss: 0.3628 - val_acc: 0.9610\n",
      "Epoch 584/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0314 - acc: 0.9947 - val_loss: 0.3774 - val_acc: 0.9490\n",
      "Epoch 585/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0291 - acc: 0.9942 - val_loss: 0.3534 - val_acc: 0.9550\n",
      "Epoch 586/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0386 - acc: 0.9934 - val_loss: 0.2967 - val_acc: 0.9620\n",
      "Epoch 587/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0241 - acc: 0.9944 - val_loss: 0.3398 - val_acc: 0.9590\n",
      "Epoch 588/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0311 - acc: 0.9944 - val_loss: 0.3221 - val_acc: 0.9590\n",
      "Epoch 589/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0342 - acc: 0.9937 - val_loss: 0.3186 - val_acc: 0.9570\n",
      "Epoch 590/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0285 - acc: 0.9953 - val_loss: 0.3353 - val_acc: 0.9510\n",
      "Epoch 591/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0358 - acc: 0.9943 - val_loss: 0.3482 - val_acc: 0.9530\n",
      "Epoch 592/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0314 - acc: 0.9938 - val_loss: 0.3208 - val_acc: 0.9490\n",
      "Epoch 593/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0314 - acc: 0.9953 - val_loss: 0.4013 - val_acc: 0.9520\n",
      "Epoch 594/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0359 - acc: 0.9944 - val_loss: 0.4076 - val_acc: 0.9520\n",
      "Epoch 595/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0227 - acc: 0.9947 - val_loss: 0.4532 - val_acc: 0.9460\n",
      "Epoch 596/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0267 - acc: 0.9946 - val_loss: 0.4178 - val_acc: 0.9470\n",
      "Epoch 597/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0280 - acc: 0.9947 - val_loss: 0.3577 - val_acc: 0.9460\n",
      "Epoch 598/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0323 - acc: 0.9939 - val_loss: 0.3369 - val_acc: 0.9600\n",
      "Epoch 599/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0296 - acc: 0.9943 - val_loss: 0.4047 - val_acc: 0.9510\n",
      "Epoch 600/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0312 - acc: 0.9938 - val_loss: 0.3558 - val_acc: 0.9510\n",
      "Epoch 601/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0328 - acc: 0.9937 - val_loss: 0.2784 - val_acc: 0.9630\n",
      "Epoch 602/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0249 - acc: 0.9945 - val_loss: 0.3049 - val_acc: 0.9580\n",
      "Epoch 603/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0259 - acc: 0.9952 - val_loss: 0.4000 - val_acc: 0.9530\n",
      "Epoch 604/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0292 - acc: 0.9941 - val_loss: 0.3662 - val_acc: 0.9530\n",
      "Epoch 605/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0298 - acc: 0.9942 - val_loss: 0.3367 - val_acc: 0.9560\n",
      "Epoch 606/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0305 - acc: 0.9936 - val_loss: 0.3549 - val_acc: 0.9540\n",
      "Epoch 607/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0451 - acc: 0.9922 - val_loss: 0.3491 - val_acc: 0.9530\n",
      "Epoch 608/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0393 - acc: 0.9941 - val_loss: 0.3343 - val_acc: 0.9500\n",
      "Epoch 609/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0254 - acc: 0.9943 - val_loss: 0.3871 - val_acc: 0.9540\n",
      "Epoch 610/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0394 - acc: 0.9942 - val_loss: 0.4002 - val_acc: 0.9520\n",
      "Epoch 611/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0298 - acc: 0.9943 - val_loss: 0.4013 - val_acc: 0.9490\n",
      "Epoch 612/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.0317 - acc: 0.9942 - val_loss: 0.3584 - val_acc: 0.9570\n",
      "Epoch 613/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.0321 - acc: 0.9943 - val_loss: 0.3954 - val_acc: 0.9500\n",
      "Epoch 614/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0240 - acc: 0.9955 - val_loss: 0.3994 - val_acc: 0.9470\n",
      "Epoch 615/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0519 - acc: 0.9909 - val_loss: 0.3499 - val_acc: 0.9510\n",
      "Epoch 616/1000\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0292 - acc: 0.994 - 4s 378us/step - loss: 0.0289 - acc: 0.9941 - val_loss: 0.3515 - val_acc: 0.9500\n",
      "Epoch 617/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0281 - acc: 0.9946 - val_loss: 0.4376 - val_acc: 0.9490\n",
      "Epoch 618/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0372 - acc: 0.9934 - val_loss: 0.3475 - val_acc: 0.9520\n",
      "Epoch 619/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0294 - acc: 0.9948 - val_loss: 0.4249 - val_acc: 0.9510\n",
      "Epoch 620/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0287 - acc: 0.9939 - val_loss: 0.4180 - val_acc: 0.9500\n",
      "Epoch 621/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0301 - acc: 0.9948 - val_loss: 0.4523 - val_acc: 0.9490\n",
      "Epoch 622/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0321 - acc: 0.9947 - val_loss: 0.3751 - val_acc: 0.9500\n",
      "Epoch 623/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0281 - acc: 0.9942 - val_loss: 0.4066 - val_acc: 0.9540\n",
      "Epoch 624/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0301 - acc: 0.9951 - val_loss: 0.4103 - val_acc: 0.9520\n",
      "Epoch 625/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0280 - acc: 0.9933 - val_loss: 0.4027 - val_acc: 0.9570\n",
      "Epoch 626/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0338 - acc: 0.9951 - val_loss: 0.4288 - val_acc: 0.9540\n",
      "Epoch 627/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0268 - acc: 0.9943 - val_loss: 0.3919 - val_acc: 0.9600\n",
      "Epoch 628/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0384 - acc: 0.9941 - val_loss: 0.3666 - val_acc: 0.9620\n",
      "Epoch 629/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0371 - acc: 0.9943 - val_loss: 0.3855 - val_acc: 0.9520\n",
      "Epoch 630/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0419 - acc: 0.9935 - val_loss: 0.3634 - val_acc: 0.9530\n",
      "Epoch 631/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0311 - acc: 0.9942 - val_loss: 0.4153 - val_acc: 0.9520\n",
      "Epoch 632/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0248 - acc: 0.9953 - val_loss: 0.3933 - val_acc: 0.9530\n",
      "Epoch 633/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0245 - acc: 0.9959 - val_loss: 0.4738 - val_acc: 0.9490\n",
      "Epoch 634/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0351 - acc: 0.9942 - val_loss: 0.3553 - val_acc: 0.9500\n",
      "Epoch 635/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0281 - acc: 0.9945 - val_loss: 0.3720 - val_acc: 0.9500\n",
      "Epoch 636/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0366 - acc: 0.9935 - val_loss: 0.3573 - val_acc: 0.9540\n",
      "Epoch 637/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0363 - acc: 0.9919 - val_loss: 0.3612 - val_acc: 0.9560\n",
      "Epoch 638/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.0286 - acc: 0.9953 - val_loss: 0.3003 - val_acc: 0.9590\n",
      "Epoch 639/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0323 - acc: 0.9931 - val_loss: 0.3275 - val_acc: 0.9560\n",
      "Epoch 640/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0322 - acc: 0.9940 - val_loss: 0.3666 - val_acc: 0.9420\n",
      "Epoch 641/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0305 - acc: 0.9942 - val_loss: 0.3196 - val_acc: 0.9540\n",
      "Epoch 642/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0300 - acc: 0.9943 - val_loss: 0.2542 - val_acc: 0.9540\n",
      "Epoch 643/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0283 - acc: 0.9949 - val_loss: 0.3916 - val_acc: 0.9460\n",
      "Epoch 644/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0297 - acc: 0.9946 - val_loss: 0.2919 - val_acc: 0.9560\n",
      "Epoch 645/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0253 - acc: 0.9953 - val_loss: 0.3374 - val_acc: 0.9550\n",
      "Epoch 646/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0418 - acc: 0.9928 - val_loss: 0.3380 - val_acc: 0.9600\n",
      "Epoch 647/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0303 - acc: 0.9938 - val_loss: 0.3005 - val_acc: 0.9560\n",
      "Epoch 648/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0361 - acc: 0.9942 - val_loss: 0.3826 - val_acc: 0.9530\n",
      "Epoch 649/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0281 - acc: 0.9940 - val_loss: 0.3488 - val_acc: 0.9570\n",
      "Epoch 650/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0311 - acc: 0.9945 - val_loss: 0.3269 - val_acc: 0.9600\n",
      "Epoch 651/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0266 - acc: 0.9949 - val_loss: 0.3521 - val_acc: 0.9590\n",
      "Epoch 652/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0248 - acc: 0.9952 - val_loss: 0.3689 - val_acc: 0.9540\n",
      "Epoch 653/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0318 - acc: 0.9934 - val_loss: 0.3806 - val_acc: 0.9520\n",
      "Epoch 654/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0298 - acc: 0.9946 - val_loss: 0.3561 - val_acc: 0.9530\n",
      "Epoch 655/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0376 - acc: 0.9942 - val_loss: 0.3129 - val_acc: 0.9600\n",
      "Epoch 656/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0306 - acc: 0.9946 - val_loss: 0.4441 - val_acc: 0.9430\n",
      "Epoch 657/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0279 - acc: 0.9947 - val_loss: 0.3698 - val_acc: 0.9570\n",
      "Epoch 658/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0285 - acc: 0.9947 - val_loss: 0.3887 - val_acc: 0.9570\n",
      "Epoch 659/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0247 - acc: 0.9950 - val_loss: 0.3980 - val_acc: 0.9560\n",
      "Epoch 660/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0308 - acc: 0.9943 - val_loss: 0.4201 - val_acc: 0.9380\n",
      "Epoch 661/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0255 - acc: 0.9954 - val_loss: 0.3610 - val_acc: 0.9570\n",
      "Epoch 662/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0318 - acc: 0.9937 - val_loss: 0.3430 - val_acc: 0.9580\n",
      "Epoch 663/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0248 - acc: 0.9952 - val_loss: 0.3295 - val_acc: 0.9610\n",
      "Epoch 664/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0314 - acc: 0.9950 - val_loss: 0.3760 - val_acc: 0.9600\n",
      "Epoch 665/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0311 - acc: 0.9945 - val_loss: 0.3302 - val_acc: 0.9580\n",
      "Epoch 666/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0316 - acc: 0.9934 - val_loss: 0.3740 - val_acc: 0.9540\n",
      "Epoch 667/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0284 - acc: 0.9949 - val_loss: 0.3808 - val_acc: 0.9520\n",
      "Epoch 668/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0277 - acc: 0.9948 - val_loss: 0.3388 - val_acc: 0.9600\n",
      "Epoch 669/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0331 - acc: 0.9943 - val_loss: 0.3485 - val_acc: 0.9560\n",
      "Epoch 670/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0292 - acc: 0.9959 - val_loss: 0.3903 - val_acc: 0.9580\n",
      "Epoch 671/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0284 - acc: 0.9957 - val_loss: 0.3335 - val_acc: 0.9550\n",
      "Epoch 672/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0436 - acc: 0.9937 - val_loss: 0.3756 - val_acc: 0.9540\n",
      "Epoch 673/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0358 - acc: 0.9938 - val_loss: 0.3342 - val_acc: 0.9620\n",
      "Epoch 674/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0311 - acc: 0.9940 - val_loss: 0.3652 - val_acc: 0.9530\n",
      "Epoch 675/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0355 - acc: 0.9940 - val_loss: 0.2969 - val_acc: 0.9640\n",
      "Epoch 676/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0295 - acc: 0.9951 - val_loss: 0.3027 - val_acc: 0.9560\n",
      "Epoch 677/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0341 - acc: 0.9945 - val_loss: 0.3499 - val_acc: 0.9580\n",
      "Epoch 678/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0265 - acc: 0.9947 - val_loss: 0.3306 - val_acc: 0.9520\n",
      "Epoch 679/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0346 - acc: 0.9932 - val_loss: 0.3706 - val_acc: 0.9540\n",
      "Epoch 680/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0381 - acc: 0.9931 - val_loss: 0.3266 - val_acc: 0.9500\n",
      "Epoch 681/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0310 - acc: 0.9947 - val_loss: 0.3687 - val_acc: 0.9460\n",
      "Epoch 682/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0351 - acc: 0.9936 - val_loss: 0.3768 - val_acc: 0.9450\n",
      "Epoch 683/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0341 - acc: 0.9952 - val_loss: 0.3664 - val_acc: 0.9580\n",
      "Epoch 684/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0360 - acc: 0.9940 - val_loss: 0.3720 - val_acc: 0.9520\n",
      "Epoch 685/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0317 - acc: 0.9950 - val_loss: 0.3779 - val_acc: 0.9450\n",
      "Epoch 686/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0360 - acc: 0.9942 - val_loss: 0.3732 - val_acc: 0.9530\n",
      "Epoch 687/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0421 - acc: 0.9941 - val_loss: 0.2872 - val_acc: 0.9560\n",
      "Epoch 688/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0339 - acc: 0.9931 - val_loss: 0.3297 - val_acc: 0.9570\n",
      "Epoch 689/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0255 - acc: 0.9955 - val_loss: 0.4185 - val_acc: 0.9500\n",
      "Epoch 690/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0319 - acc: 0.9936 - val_loss: 0.4096 - val_acc: 0.9480\n",
      "Epoch 691/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0366 - acc: 0.9926 - val_loss: 0.3798 - val_acc: 0.9510\n",
      "Epoch 692/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0284 - acc: 0.9944 - val_loss: 0.3790 - val_acc: 0.9530\n",
      "Epoch 693/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0408 - acc: 0.9929 - val_loss: 0.3577 - val_acc: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0292 - acc: 0.9941 - val_loss: 0.3774 - val_acc: 0.9540\n",
      "Epoch 695/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0322 - acc: 0.9948 - val_loss: 0.3958 - val_acc: 0.9510\n",
      "Epoch 696/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0376 - acc: 0.9935 - val_loss: 0.3697 - val_acc: 0.9500\n",
      "Epoch 697/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0290 - acc: 0.9946 - val_loss: 0.4402 - val_acc: 0.9500\n",
      "Epoch 698/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0342 - acc: 0.9925 - val_loss: 0.3568 - val_acc: 0.9560\n",
      "Epoch 699/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0300 - acc: 0.9951 - val_loss: 0.3532 - val_acc: 0.9540\n",
      "Epoch 700/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0430 - acc: 0.9925 - val_loss: 0.4189 - val_acc: 0.9550\n",
      "Epoch 701/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0340 - acc: 0.9941 - val_loss: 0.3497 - val_acc: 0.9580\n",
      "Epoch 702/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0309 - acc: 0.9931 - val_loss: 0.3400 - val_acc: 0.9560\n",
      "Epoch 703/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0456 - acc: 0.9916 - val_loss: 0.3400 - val_acc: 0.9540\n",
      "Epoch 704/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0397 - acc: 0.9931 - val_loss: 0.3229 - val_acc: 0.9540\n",
      "Epoch 705/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0298 - acc: 0.9950 - val_loss: 0.3786 - val_acc: 0.9550\n",
      "Epoch 706/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0262 - acc: 0.9950 - val_loss: 0.3632 - val_acc: 0.9560\n",
      "Epoch 707/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0318 - acc: 0.9945 - val_loss: 0.3530 - val_acc: 0.9600\n",
      "Epoch 708/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0261 - acc: 0.9947 - val_loss: 0.3437 - val_acc: 0.9550\n",
      "Epoch 709/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0394 - acc: 0.9932 - val_loss: 0.3501 - val_acc: 0.9610\n",
      "Epoch 710/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0313 - acc: 0.9943 - val_loss: 0.3603 - val_acc: 0.9510\n",
      "Epoch 711/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0303 - acc: 0.9942 - val_loss: 0.3408 - val_acc: 0.9530\n",
      "Epoch 712/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0417 - acc: 0.9935 - val_loss: 0.3208 - val_acc: 0.9530\n",
      "Epoch 713/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0318 - acc: 0.9945 - val_loss: 0.3892 - val_acc: 0.9560\n",
      "Epoch 714/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0334 - acc: 0.9946 - val_loss: 0.4224 - val_acc: 0.9450\n",
      "Epoch 715/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0471 - acc: 0.9920 - val_loss: 0.3085 - val_acc: 0.9560\n",
      "Epoch 716/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0406 - acc: 0.9937 - val_loss: 0.3298 - val_acc: 0.9580\n",
      "Epoch 717/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0359 - acc: 0.9937 - val_loss: 0.3363 - val_acc: 0.9540\n",
      "Epoch 718/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0448 - acc: 0.9920 - val_loss: 0.3091 - val_acc: 0.9560\n",
      "Epoch 719/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0359 - acc: 0.9938 - val_loss: 0.3794 - val_acc: 0.9490\n",
      "Epoch 720/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0375 - acc: 0.9933 - val_loss: 0.3761 - val_acc: 0.9540\n",
      "Epoch 721/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0392 - acc: 0.9927 - val_loss: 0.3030 - val_acc: 0.9530\n",
      "Epoch 722/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0445 - acc: 0.9913 - val_loss: 0.3468 - val_acc: 0.9550\n",
      "Epoch 723/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0311 - acc: 0.9933 - val_loss: 0.3550 - val_acc: 0.9510\n",
      "Epoch 724/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0398 - acc: 0.9925 - val_loss: 0.3921 - val_acc: 0.9510\n",
      "Epoch 725/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0305 - acc: 0.9942 - val_loss: 0.3867 - val_acc: 0.9530\n",
      "Epoch 726/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0376 - acc: 0.9928 - val_loss: 0.3524 - val_acc: 0.9560\n",
      "Epoch 727/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0450 - acc: 0.9923 - val_loss: 0.3352 - val_acc: 0.9520\n",
      "Epoch 728/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0340 - acc: 0.9941 - val_loss: 0.3359 - val_acc: 0.9570\n",
      "Epoch 729/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0409 - acc: 0.9913 - val_loss: 0.2724 - val_acc: 0.9590\n",
      "Epoch 730/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0342 - acc: 0.9936 - val_loss: 0.3538 - val_acc: 0.9470\n",
      "Epoch 731/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0467 - acc: 0.9920 - val_loss: 0.3892 - val_acc: 0.9530\n",
      "Epoch 732/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0368 - acc: 0.9947 - val_loss: 0.3271 - val_acc: 0.9520\n",
      "Epoch 733/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0391 - acc: 0.9933 - val_loss: 0.3376 - val_acc: 0.9510\n",
      "Epoch 734/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0362 - acc: 0.9933 - val_loss: 0.3596 - val_acc: 0.9450\n",
      "Epoch 735/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0417 - acc: 0.9932 - val_loss: 0.3620 - val_acc: 0.9570\n",
      "Epoch 736/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0343 - acc: 0.9933 - val_loss: 0.2988 - val_acc: 0.9580\n",
      "Epoch 737/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0373 - acc: 0.9935 - val_loss: 0.3477 - val_acc: 0.9490\n",
      "Epoch 738/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0391 - acc: 0.9925 - val_loss: 0.3842 - val_acc: 0.9540\n",
      "Epoch 739/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0487 - acc: 0.9917 - val_loss: 0.3329 - val_acc: 0.9550\n",
      "Epoch 740/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0421 - acc: 0.9920 - val_loss: 0.3180 - val_acc: 0.9510\n",
      "Epoch 741/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0421 - acc: 0.9921 - val_loss: 0.3562 - val_acc: 0.9510\n",
      "Epoch 742/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0415 - acc: 0.9926 - val_loss: 0.3802 - val_acc: 0.9500\n",
      "Epoch 743/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0418 - acc: 0.9921 - val_loss: 0.3612 - val_acc: 0.9430\n",
      "Epoch 744/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0352 - acc: 0.9935 - val_loss: 0.3716 - val_acc: 0.9490\n",
      "Epoch 745/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0362 - acc: 0.9942 - val_loss: 0.3787 - val_acc: 0.9510\n",
      "Epoch 746/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0326 - acc: 0.9931 - val_loss: 0.3966 - val_acc: 0.9450\n",
      "Epoch 747/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0380 - acc: 0.9934 - val_loss: 0.3375 - val_acc: 0.9550\n",
      "Epoch 748/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0336 - acc: 0.9950 - val_loss: 0.3515 - val_acc: 0.9600\n",
      "Epoch 749/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0341 - acc: 0.9944 - val_loss: 0.3564 - val_acc: 0.9480\n",
      "Epoch 750/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0428 - acc: 0.9932 - val_loss: 0.3492 - val_acc: 0.9510\n",
      "Epoch 751/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0416 - acc: 0.9929 - val_loss: 0.3135 - val_acc: 0.9540\n",
      "Epoch 752/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0378 - acc: 0.9930 - val_loss: 0.2920 - val_acc: 0.9480\n",
      "Epoch 753/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0371 - acc: 0.9923 - val_loss: 0.3567 - val_acc: 0.9480\n",
      "Epoch 754/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0395 - acc: 0.9923 - val_loss: 0.3473 - val_acc: 0.9510\n",
      "Epoch 755/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0292 - acc: 0.9941 - val_loss: 0.3369 - val_acc: 0.9520\n",
      "Epoch 756/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0349 - acc: 0.9931 - val_loss: 0.2934 - val_acc: 0.9550\n",
      "Epoch 757/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0293 - acc: 0.9937 - val_loss: 0.4016 - val_acc: 0.9530\n",
      "Epoch 758/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0477 - acc: 0.9930 - val_loss: 0.4017 - val_acc: 0.9420\n",
      "Epoch 759/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0336 - acc: 0.9936 - val_loss: 0.3799 - val_acc: 0.9500\n",
      "Epoch 760/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0375 - acc: 0.9931 - val_loss: 0.3552 - val_acc: 0.9500\n",
      "Epoch 761/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0428 - acc: 0.9932 - val_loss: 0.3694 - val_acc: 0.9490\n",
      "Epoch 762/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0386 - acc: 0.9934 - val_loss: 0.3474 - val_acc: 0.9490\n",
      "Epoch 763/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0437 - acc: 0.9932 - val_loss: 0.3492 - val_acc: 0.9450\n",
      "Epoch 764/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0324 - acc: 0.9936 - val_loss: 0.3896 - val_acc: 0.9520\n",
      "Epoch 765/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0371 - acc: 0.9938 - val_loss: 0.3397 - val_acc: 0.9570\n",
      "Epoch 766/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0361 - acc: 0.9941 - val_loss: 0.3807 - val_acc: 0.9530\n",
      "Epoch 767/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0360 - acc: 0.9930 - val_loss: 0.3584 - val_acc: 0.9610\n",
      "Epoch 768/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0309 - acc: 0.9956 - val_loss: 0.3778 - val_acc: 0.9490\n",
      "Epoch 769/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0379 - acc: 0.9940 - val_loss: 0.3556 - val_acc: 0.9560\n",
      "Epoch 770/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0291 - acc: 0.9940 - val_loss: 0.3910 - val_acc: 0.9510\n",
      "Epoch 771/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0391 - acc: 0.9938 - val_loss: 0.3820 - val_acc: 0.9530\n",
      "Epoch 772/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0403 - acc: 0.9931 - val_loss: 0.3253 - val_acc: 0.9510\n",
      "Epoch 773/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0370 - acc: 0.9918 - val_loss: 0.3725 - val_acc: 0.9500\n",
      "Epoch 774/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0396 - acc: 0.9931 - val_loss: 0.3815 - val_acc: 0.9450\n",
      "Epoch 775/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0267 - acc: 0.9953 - val_loss: 0.3594 - val_acc: 0.9480\n",
      "Epoch 776/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0395 - acc: 0.9940 - val_loss: 0.3638 - val_acc: 0.9460\n",
      "Epoch 777/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0402 - acc: 0.9939 - val_loss: 0.3898 - val_acc: 0.9560\n",
      "Epoch 778/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0415 - acc: 0.9934 - val_loss: 0.3200 - val_acc: 0.9450\n",
      "Epoch 779/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0368 - acc: 0.9923 - val_loss: 0.3480 - val_acc: 0.9560\n",
      "Epoch 780/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0386 - acc: 0.9952 - val_loss: 0.3070 - val_acc: 0.9600\n",
      "Epoch 781/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0334 - acc: 0.9932 - val_loss: 0.3163 - val_acc: 0.9570\n",
      "Epoch 782/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0313 - acc: 0.9937 - val_loss: 0.3581 - val_acc: 0.9580\n",
      "Epoch 783/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0372 - acc: 0.9935 - val_loss: 0.3651 - val_acc: 0.9600\n",
      "Epoch 784/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0403 - acc: 0.9926 - val_loss: 0.3845 - val_acc: 0.9560\n",
      "Epoch 785/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0334 - acc: 0.9930 - val_loss: 0.3653 - val_acc: 0.9510\n",
      "Epoch 786/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0340 - acc: 0.9946 - val_loss: 0.3779 - val_acc: 0.9560\n",
      "Epoch 787/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0348 - acc: 0.9940 - val_loss: 0.3179 - val_acc: 0.9610\n",
      "Epoch 788/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0387 - acc: 0.9940 - val_loss: 0.2968 - val_acc: 0.9620\n",
      "Epoch 789/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0365 - acc: 0.9934 - val_loss: 0.3835 - val_acc: 0.9440\n",
      "Epoch 790/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0406 - acc: 0.9932 - val_loss: 0.3188 - val_acc: 0.9420\n",
      "Epoch 791/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0365 - acc: 0.9940 - val_loss: 0.3524 - val_acc: 0.9510\n",
      "Epoch 792/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0419 - acc: 0.9923 - val_loss: 0.3181 - val_acc: 0.9580\n",
      "Epoch 793/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0410 - acc: 0.9918 - val_loss: 0.3443 - val_acc: 0.9550\n",
      "Epoch 794/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0409 - acc: 0.9924 - val_loss: 0.3368 - val_acc: 0.9570\n",
      "Epoch 795/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0422 - acc: 0.9927 - val_loss: 0.3162 - val_acc: 0.9560\n",
      "Epoch 796/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0296 - acc: 0.9943 - val_loss: 0.3919 - val_acc: 0.9560\n",
      "Epoch 797/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0414 - acc: 0.9925 - val_loss: 0.3500 - val_acc: 0.9590\n",
      "Epoch 798/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0352 - acc: 0.9947 - val_loss: 0.4281 - val_acc: 0.9490\n",
      "Epoch 799/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0422 - acc: 0.9935 - val_loss: 0.3461 - val_acc: 0.9500\n",
      "Epoch 800/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0382 - acc: 0.9936 - val_loss: 0.3132 - val_acc: 0.9560\n",
      "Epoch 801/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0288 - acc: 0.9942 - val_loss: 0.3773 - val_acc: 0.9520\n",
      "Epoch 802/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0413 - acc: 0.9925 - val_loss: 0.3386 - val_acc: 0.9550\n",
      "Epoch 803/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0448 - acc: 0.9920 - val_loss: 0.2970 - val_acc: 0.9590\n",
      "Epoch 804/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0374 - acc: 0.9929 - val_loss: 0.2758 - val_acc: 0.9630\n",
      "Epoch 805/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0395 - acc: 0.9930 - val_loss: 0.3368 - val_acc: 0.9620\n",
      "Epoch 806/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0456 - acc: 0.9942 - val_loss: 0.3279 - val_acc: 0.9530\n",
      "Epoch 807/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0300 - acc: 0.9942 - val_loss: 0.3540 - val_acc: 0.9570\n",
      "Epoch 808/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0325 - acc: 0.9939 - val_loss: 0.3611 - val_acc: 0.9540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 809/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0394 - acc: 0.9913 - val_loss: 0.3140 - val_acc: 0.9490\n",
      "Epoch 810/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0385 - acc: 0.9939 - val_loss: 0.3380 - val_acc: 0.9580\n",
      "Epoch 811/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0383 - acc: 0.9945 - val_loss: 0.3645 - val_acc: 0.9520\n",
      "Epoch 812/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0324 - acc: 0.9940 - val_loss: 0.3256 - val_acc: 0.9540\n",
      "Epoch 813/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0456 - acc: 0.9919 - val_loss: 0.3170 - val_acc: 0.9580\n",
      "Epoch 814/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0411 - acc: 0.9932 - val_loss: 0.4066 - val_acc: 0.9520\n",
      "Epoch 815/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0361 - acc: 0.9935 - val_loss: 0.3588 - val_acc: 0.9620\n",
      "Epoch 816/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0421 - acc: 0.9931 - val_loss: 0.3496 - val_acc: 0.9550\n",
      "Epoch 817/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0401 - acc: 0.9931 - val_loss: 0.3344 - val_acc: 0.9580\n",
      "Epoch 818/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0358 - acc: 0.9938 - val_loss: 0.3254 - val_acc: 0.9570\n",
      "Epoch 819/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0433 - acc: 0.9920 - val_loss: 0.3173 - val_acc: 0.9510\n",
      "Epoch 820/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0384 - acc: 0.9931 - val_loss: 0.3587 - val_acc: 0.9580\n",
      "Epoch 821/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0386 - acc: 0.9936 - val_loss: 0.3394 - val_acc: 0.9540\n",
      "Epoch 822/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0292 - acc: 0.9949 - val_loss: 0.3697 - val_acc: 0.9520\n",
      "Epoch 823/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0456 - acc: 0.9929 - val_loss: 0.3179 - val_acc: 0.9570\n",
      "Epoch 824/1000\n",
      "10000/10000 [==============================] - 4s 370us/step - loss: 0.0312 - acc: 0.9933 - val_loss: 0.3712 - val_acc: 0.9540\n",
      "Epoch 825/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0424 - acc: 0.9930 - val_loss: 0.3348 - val_acc: 0.9570\n",
      "Epoch 826/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0395 - acc: 0.9939 - val_loss: 0.3070 - val_acc: 0.9570\n",
      "Epoch 827/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0374 - acc: 0.9937 - val_loss: 0.3084 - val_acc: 0.9620\n",
      "Epoch 828/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0338 - acc: 0.9934 - val_loss: 0.2910 - val_acc: 0.9630\n",
      "Epoch 829/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0380 - acc: 0.9935 - val_loss: 0.3196 - val_acc: 0.9560\n",
      "Epoch 830/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0433 - acc: 0.9921 - val_loss: 0.3074 - val_acc: 0.9550\n",
      "Epoch 831/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0293 - acc: 0.9948 - val_loss: 0.3050 - val_acc: 0.9530\n",
      "Epoch 832/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0372 - acc: 0.9920 - val_loss: 0.3325 - val_acc: 0.9550\n",
      "Epoch 833/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0421 - acc: 0.9928 - val_loss: 0.3469 - val_acc: 0.9470\n",
      "Epoch 834/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0364 - acc: 0.9942 - val_loss: 0.3532 - val_acc: 0.9550\n",
      "Epoch 835/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0356 - acc: 0.9928 - val_loss: 0.3302 - val_acc: 0.9590\n",
      "Epoch 836/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0360 - acc: 0.9946 - val_loss: 0.3862 - val_acc: 0.9530\n",
      "Epoch 837/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0377 - acc: 0.9942 - val_loss: 0.3471 - val_acc: 0.9580\n",
      "Epoch 838/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0304 - acc: 0.9942 - val_loss: 0.3654 - val_acc: 0.9580\n",
      "Epoch 839/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0551 - acc: 0.9917 - val_loss: 0.3172 - val_acc: 0.9610\n",
      "Epoch 840/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0444 - acc: 0.9920 - val_loss: 0.3216 - val_acc: 0.9520\n",
      "Epoch 841/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0372 - acc: 0.9928 - val_loss: 0.3723 - val_acc: 0.9550\n",
      "Epoch 842/1000\n",
      "10000/10000 [==============================] - 4s 372us/step - loss: 0.0447 - acc: 0.9925 - val_loss: 0.3456 - val_acc: 0.9560\n",
      "Epoch 843/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0417 - acc: 0.9930 - val_loss: 0.3171 - val_acc: 0.9580\n",
      "Epoch 844/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0368 - acc: 0.9927 - val_loss: 0.2779 - val_acc: 0.9590\n",
      "Epoch 845/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0497 - acc: 0.9915 - val_loss: 0.2923 - val_acc: 0.9650\n",
      "Epoch 846/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0349 - acc: 0.9937 - val_loss: 0.3148 - val_acc: 0.9600\n",
      "Epoch 847/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0418 - acc: 0.9927 - val_loss: 0.2987 - val_acc: 0.9610\n",
      "Epoch 848/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0424 - acc: 0.9926 - val_loss: 0.3270 - val_acc: 0.9580\n",
      "Epoch 849/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0300 - acc: 0.9946 - val_loss: 0.3165 - val_acc: 0.9540\n",
      "Epoch 850/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0373 - acc: 0.9931 - val_loss: 0.3158 - val_acc: 0.9550\n",
      "Epoch 851/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0326 - acc: 0.9949 - val_loss: 0.3540 - val_acc: 0.9570\n",
      "Epoch 852/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0438 - acc: 0.9924 - val_loss: 0.3529 - val_acc: 0.9560\n",
      "Epoch 853/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0479 - acc: 0.9922 - val_loss: 0.3394 - val_acc: 0.9500\n",
      "Epoch 854/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0426 - acc: 0.9917 - val_loss: 0.3629 - val_acc: 0.9540\n",
      "Epoch 855/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0402 - acc: 0.9926 - val_loss: 0.2700 - val_acc: 0.9610\n",
      "Epoch 856/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0482 - acc: 0.9917 - val_loss: 0.3194 - val_acc: 0.9550\n",
      "Epoch 857/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0404 - acc: 0.9934 - val_loss: 0.3355 - val_acc: 0.9530\n",
      "Epoch 858/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.0471 - acc: 0.9916 - val_loss: 0.3130 - val_acc: 0.9530\n",
      "Epoch 859/1000\n",
      "10000/10000 [==============================] - 4s 386us/step - loss: 0.0419 - acc: 0.9927 - val_loss: 0.2566 - val_acc: 0.9570\n",
      "Epoch 860/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0436 - acc: 0.9924 - val_loss: 0.2977 - val_acc: 0.9530\n",
      "Epoch 861/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0383 - acc: 0.9932 - val_loss: 0.3365 - val_acc: 0.9560\n",
      "Epoch 862/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0374 - acc: 0.9933 - val_loss: 0.3032 - val_acc: 0.9560\n",
      "Epoch 863/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0413 - acc: 0.9934 - val_loss: 0.3506 - val_acc: 0.9530\n",
      "Epoch 864/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0414 - acc: 0.9935 - val_loss: 0.3066 - val_acc: 0.9510\n",
      "Epoch 865/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0404 - acc: 0.9930 - val_loss: 0.3477 - val_acc: 0.9510\n",
      "Epoch 866/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0422 - acc: 0.9932 - val_loss: 0.3321 - val_acc: 0.9510\n",
      "Epoch 867/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0394 - acc: 0.9936 - val_loss: 0.3577 - val_acc: 0.9540\n",
      "Epoch 868/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0380 - acc: 0.9931 - val_loss: 0.3838 - val_acc: 0.9550\n",
      "Epoch 869/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0494 - acc: 0.9926 - val_loss: 0.2908 - val_acc: 0.9530\n",
      "Epoch 870/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0371 - acc: 0.9932 - val_loss: 0.3530 - val_acc: 0.9500\n",
      "Epoch 871/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0359 - acc: 0.9943 - val_loss: 0.3556 - val_acc: 0.9510\n",
      "Epoch 872/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0448 - acc: 0.9932 - val_loss: 0.3084 - val_acc: 0.9550\n",
      "Epoch 873/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0475 - acc: 0.9929 - val_loss: 0.3174 - val_acc: 0.9510\n",
      "Epoch 874/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0313 - acc: 0.9933 - val_loss: 0.2967 - val_acc: 0.9470\n",
      "Epoch 875/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0489 - acc: 0.9922 - val_loss: 0.3577 - val_acc: 0.9570\n",
      "Epoch 876/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0484 - acc: 0.9926 - val_loss: 0.3219 - val_acc: 0.9580\n",
      "Epoch 877/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0496 - acc: 0.9924 - val_loss: 0.3254 - val_acc: 0.9610\n",
      "Epoch 878/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0538 - acc: 0.9914 - val_loss: 0.2941 - val_acc: 0.9570\n",
      "Epoch 879/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0447 - acc: 0.9927 - val_loss: 0.3427 - val_acc: 0.9620\n",
      "Epoch 880/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0367 - acc: 0.9932 - val_loss: 0.3908 - val_acc: 0.9590\n",
      "Epoch 881/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0569 - acc: 0.9917 - val_loss: 0.4197 - val_acc: 0.9540\n",
      "Epoch 882/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0370 - acc: 0.9937 - val_loss: 0.3504 - val_acc: 0.9600\n",
      "Epoch 883/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0530 - acc: 0.9919 - val_loss: 0.3138 - val_acc: 0.9580\n",
      "Epoch 884/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0374 - acc: 0.9939 - val_loss: 0.3239 - val_acc: 0.9560\n",
      "Epoch 885/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0477 - acc: 0.9934 - val_loss: 0.3656 - val_acc: 0.9570\n",
      "Epoch 886/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0532 - acc: 0.9922 - val_loss: 0.2914 - val_acc: 0.9580\n",
      "Epoch 887/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.0274 - acc: 0.9948 - val_loss: 0.3448 - val_acc: 0.9550\n",
      "Epoch 888/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0487 - acc: 0.9922 - val_loss: 0.3653 - val_acc: 0.9510\n",
      "Epoch 889/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0550 - acc: 0.9920 - val_loss: 0.2915 - val_acc: 0.9550\n",
      "Epoch 890/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0355 - acc: 0.9942 - val_loss: 0.2933 - val_acc: 0.9590\n",
      "Epoch 891/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0447 - acc: 0.9922 - val_loss: 0.3282 - val_acc: 0.9540\n",
      "Epoch 892/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0416 - acc: 0.9938 - val_loss: 0.3182 - val_acc: 0.9520\n",
      "Epoch 893/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0597 - acc: 0.9902 - val_loss: 0.3063 - val_acc: 0.9600\n",
      "Epoch 894/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0450 - acc: 0.9923 - val_loss: 0.2733 - val_acc: 0.9530\n",
      "Epoch 895/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0486 - acc: 0.9905 - val_loss: 0.2506 - val_acc: 0.9630\n",
      "Epoch 896/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0444 - acc: 0.9923 - val_loss: 0.3139 - val_acc: 0.9570\n",
      "Epoch 897/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0485 - acc: 0.9928 - val_loss: 0.3201 - val_acc: 0.9520\n",
      "Epoch 898/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0483 - acc: 0.9910 - val_loss: 0.3312 - val_acc: 0.9430\n",
      "Epoch 899/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0495 - acc: 0.9920 - val_loss: 0.4127 - val_acc: 0.9500\n",
      "Epoch 900/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0628 - acc: 0.9905 - val_loss: 0.2758 - val_acc: 0.9530\n",
      "Epoch 901/1000\n",
      "10000/10000 [==============================] - 4s 401us/step - loss: 0.0326 - acc: 0.9940 - val_loss: 0.3320 - val_acc: 0.9580\n",
      "Epoch 902/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0321 - acc: 0.9945 - val_loss: 0.3830 - val_acc: 0.9600\n",
      "Epoch 903/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0411 - acc: 0.9935 - val_loss: 0.3997 - val_acc: 0.9550\n",
      "Epoch 904/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0438 - acc: 0.9927 - val_loss: 0.3496 - val_acc: 0.9540\n",
      "Epoch 905/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0517 - acc: 0.9917 - val_loss: 0.3250 - val_acc: 0.9540\n",
      "Epoch 906/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0466 - acc: 0.9920 - val_loss: 0.2827 - val_acc: 0.9590\n",
      "Epoch 907/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0576 - acc: 0.9919 - val_loss: 0.3334 - val_acc: 0.9570\n",
      "Epoch 908/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0492 - acc: 0.9913 - val_loss: 0.3282 - val_acc: 0.9540\n",
      "Epoch 909/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0436 - acc: 0.9932 - val_loss: 0.3758 - val_acc: 0.9550\n",
      "Epoch 910/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0452 - acc: 0.9917 - val_loss: 0.2926 - val_acc: 0.9550\n",
      "Epoch 911/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0587 - acc: 0.9912 - val_loss: 0.3349 - val_acc: 0.9530\n",
      "Epoch 912/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0452 - acc: 0.9925 - val_loss: 0.2852 - val_acc: 0.9580\n",
      "Epoch 913/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0432 - acc: 0.9930 - val_loss: 0.3437 - val_acc: 0.9510\n",
      "Epoch 914/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0507 - acc: 0.9916 - val_loss: 0.3433 - val_acc: 0.9520\n",
      "Epoch 915/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0447 - acc: 0.9919 - val_loss: 0.3190 - val_acc: 0.9470\n",
      "Epoch 916/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0438 - acc: 0.9925 - val_loss: 0.3736 - val_acc: 0.9490\n",
      "Epoch 917/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0431 - acc: 0.9926 - val_loss: 0.3079 - val_acc: 0.9490\n",
      "Epoch 918/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0550 - acc: 0.9925 - val_loss: 0.2939 - val_acc: 0.9510\n",
      "Epoch 919/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0554 - acc: 0.9917 - val_loss: 0.3082 - val_acc: 0.9590\n",
      "Epoch 920/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0453 - acc: 0.9920 - val_loss: 0.3392 - val_acc: 0.9540\n",
      "Epoch 921/1000\n",
      "10000/10000 [==============================] - 4s 374us/step - loss: 0.0455 - acc: 0.9924 - val_loss: 0.2802 - val_acc: 0.9570\n",
      "Epoch 922/1000\n",
      "10000/10000 [==============================] - 4s 376us/step - loss: 0.0431 - acc: 0.9918 - val_loss: 0.2465 - val_acc: 0.9500\n",
      "Epoch 923/1000\n",
      "10000/10000 [==============================] - 4s 373us/step - loss: 0.0443 - acc: 0.9923 - val_loss: 0.3229 - val_acc: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 924/1000\n",
      "10000/10000 [==============================] - 4s 371us/step - loss: 0.0457 - acc: 0.9920 - val_loss: 0.2734 - val_acc: 0.9540\n",
      "Epoch 925/1000\n",
      "10000/10000 [==============================] - 4s 375us/step - loss: 0.0388 - acc: 0.9929 - val_loss: 0.3240 - val_acc: 0.9520\n",
      "Epoch 926/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.0492 - acc: 0.9925 - val_loss: 0.4145 - val_acc: 0.9510\n",
      "Epoch 927/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0453 - acc: 0.9930 - val_loss: 0.2556 - val_acc: 0.9600\n",
      "Epoch 928/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0459 - acc: 0.9929 - val_loss: 0.3218 - val_acc: 0.9620\n",
      "Epoch 929/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0429 - acc: 0.9927 - val_loss: 0.2723 - val_acc: 0.9570\n",
      "Epoch 930/1000\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.0557 - acc: 0.9912 - val_loss: 0.2986 - val_acc: 0.9510\n",
      "Epoch 931/1000\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.0475 - acc: 0.9936 - val_loss: 0.2555 - val_acc: 0.9640\n",
      "Epoch 932/1000\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.0436 - acc: 0.9913 - val_loss: 0.2827 - val_acc: 0.9570\n",
      "Epoch 933/1000\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.0323 - acc: 0.9929 - val_loss: 0.2331 - val_acc: 0.9620\n",
      "Epoch 934/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.0487 - acc: 0.9926 - val_loss: 0.2649 - val_acc: 0.9560\n",
      "Epoch 935/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.0484 - acc: 0.9924 - val_loss: 0.2859 - val_acc: 0.9590\n",
      "Epoch 936/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0451 - acc: 0.9923 - val_loss: 0.2632 - val_acc: 0.9570\n",
      "Epoch 937/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.0408 - acc: 0.9945 - val_loss: 0.3638 - val_acc: 0.9570\n",
      "Epoch 938/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0399 - acc: 0.9943 - val_loss: 0.3635 - val_acc: 0.9580\n",
      "Epoch 939/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.0450 - acc: 0.9923 - val_loss: 0.3057 - val_acc: 0.9590\n",
      "Epoch 940/1000\n",
      "10000/10000 [==============================] - 4s 389us/step - loss: 0.0436 - acc: 0.9933 - val_loss: 0.2599 - val_acc: 0.9620\n",
      "Epoch 941/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0480 - acc: 0.9928 - val_loss: 0.2881 - val_acc: 0.9610\n",
      "Epoch 942/1000\n",
      "10000/10000 [==============================] - 4s 377us/step - loss: 0.0489 - acc: 0.9934 - val_loss: 0.3079 - val_acc: 0.9560\n",
      "Epoch 943/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0477 - acc: 0.9937 - val_loss: 0.2990 - val_acc: 0.9550\n",
      "Epoch 944/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0463 - acc: 0.9914 - val_loss: 0.2697 - val_acc: 0.9580\n",
      "Epoch 945/1000\n",
      "10000/10000 [==============================] - 4s 383us/step - loss: 0.0380 - acc: 0.9932 - val_loss: 0.3403 - val_acc: 0.9580\n",
      "Epoch 946/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0495 - acc: 0.9932 - val_loss: 0.2952 - val_acc: 0.9570\n",
      "Epoch 947/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0384 - acc: 0.9938 - val_loss: 0.3269 - val_acc: 0.9550\n",
      "Epoch 948/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0499 - acc: 0.9922 - val_loss: 0.2972 - val_acc: 0.9610\n",
      "Epoch 949/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0499 - acc: 0.9927 - val_loss: 0.3125 - val_acc: 0.9640\n",
      "Epoch 950/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0461 - acc: 0.9923 - val_loss: 0.2667 - val_acc: 0.9570\n",
      "Epoch 951/1000\n",
      "10000/10000 [==============================] - 4s 388us/step - loss: 0.0379 - acc: 0.9944 - val_loss: 0.2961 - val_acc: 0.9630\n",
      "Epoch 952/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0325 - acc: 0.9944 - val_loss: 0.3641 - val_acc: 0.9580\n",
      "Epoch 953/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0515 - acc: 0.9928 - val_loss: 0.2466 - val_acc: 0.9650\n",
      "Epoch 954/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0378 - acc: 0.9930 - val_loss: 0.3317 - val_acc: 0.9590\n",
      "Epoch 955/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0376 - acc: 0.9938 - val_loss: 0.2902 - val_acc: 0.9580\n",
      "Epoch 956/1000\n",
      "10000/10000 [==============================] - 4s 384us/step - loss: 0.0430 - acc: 0.9929 - val_loss: 0.3320 - val_acc: 0.9500\n",
      "Epoch 957/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0378 - acc: 0.9940 - val_loss: 0.3219 - val_acc: 0.9550\n",
      "Epoch 958/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.0552 - acc: 0.9915 - val_loss: 0.3521 - val_acc: 0.9510\n",
      "Epoch 959/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0399 - acc: 0.9933 - val_loss: 0.3836 - val_acc: 0.9580\n",
      "Epoch 960/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.0467 - acc: 0.9933 - val_loss: 0.3795 - val_acc: 0.9560\n",
      "Epoch 961/1000\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.0328 - acc: 0.9935 - val_loss: 0.3109 - val_acc: 0.9640\n",
      "Epoch 962/1000\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.0439 - acc: 0.9932 - val_loss: 0.3317 - val_acc: 0.9590\n",
      "Epoch 963/1000\n",
      "10000/10000 [==============================] - 5s 493us/step - loss: 0.0411 - acc: 0.9934 - val_loss: 0.3586 - val_acc: 0.9570\n",
      "Epoch 964/1000\n",
      "10000/10000 [==============================] - 5s 487us/step - loss: 0.0459 - acc: 0.9918 - val_loss: 0.2773 - val_acc: 0.9560\n",
      "Epoch 965/1000\n",
      "10000/10000 [==============================] - 4s 399us/step - loss: 0.0487 - acc: 0.9922 - val_loss: 0.3567 - val_acc: 0.9580\n",
      "Epoch 966/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0368 - acc: 0.9922 - val_loss: 0.3179 - val_acc: 0.9580\n",
      "Epoch 967/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.0340 - acc: 0.9947 - val_loss: 0.3461 - val_acc: 0.9590\n",
      "Epoch 968/1000\n",
      "10000/10000 [==============================] - 4s 450us/step - loss: 0.0473 - acc: 0.9924 - val_loss: 0.3069 - val_acc: 0.9620\n",
      "Epoch 969/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0293 - acc: 0.9949 - val_loss: 0.3519 - val_acc: 0.9530\n",
      "Epoch 970/1000\n",
      "10000/10000 [==============================] - 4s 450us/step - loss: 0.0574 - acc: 0.9933 - val_loss: 0.3418 - val_acc: 0.9560\n",
      "Epoch 971/1000\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.0373 - acc: 0.9940 - val_loss: 0.2551 - val_acc: 0.9600\n",
      "Epoch 972/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0384 - acc: 0.9939 - val_loss: 0.2996 - val_acc: 0.9590\n",
      "Epoch 973/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0405 - acc: 0.9932 - val_loss: 0.2934 - val_acc: 0.9540\n",
      "Epoch 974/1000\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.0458 - acc: 0.9939 - val_loss: 0.3469 - val_acc: 0.9530\n",
      "Epoch 975/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0407 - acc: 0.9932 - val_loss: 0.3297 - val_acc: 0.9560\n",
      "Epoch 976/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0504 - acc: 0.9920 - val_loss: 0.2824 - val_acc: 0.9610\n",
      "Epoch 977/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0432 - acc: 0.9924 - val_loss: 0.2904 - val_acc: 0.9580\n",
      "Epoch 978/1000\n",
      "10000/10000 [==============================] - 4s 387us/step - loss: 0.0528 - acc: 0.9918 - val_loss: 0.2731 - val_acc: 0.9570\n",
      "Epoch 979/1000\n",
      "10000/10000 [==============================] - 4s 400us/step - loss: 0.0422 - acc: 0.9926 - val_loss: 0.2943 - val_acc: 0.96100411 \n",
      "Epoch 980/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0489 - acc: 0.9923 - val_loss: 0.2910 - val_acc: 0.9590\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0305 - acc: 0.9941 - val_loss: 0.3534 - val_acc: 0.9560\n",
      "Epoch 982/1000\n",
      "10000/10000 [==============================] - 4s 381us/step - loss: 0.0422 - acc: 0.9927 - val_loss: 0.3177 - val_acc: 0.9570\n",
      "Epoch 983/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0491 - acc: 0.9926 - val_loss: 0.3009 - val_acc: 0.9600\n",
      "Epoch 984/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0501 - acc: 0.9931 - val_loss: 0.3347 - val_acc: 0.9600\n",
      "Epoch 985/1000\n",
      "10000/10000 [==============================] - 4s 396us/step - loss: 0.0436 - acc: 0.9923 - val_loss: 0.3552 - val_acc: 0.9460\n",
      "Epoch 986/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.0480 - acc: 0.9925 - val_loss: 0.3314 - val_acc: 0.9560\n",
      "Epoch 987/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.0497 - acc: 0.9930 - val_loss: 0.2798 - val_acc: 0.9630\n",
      "Epoch 988/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.0397 - acc: 0.9941 - val_loss: 0.2444 - val_acc: 0.9700\n",
      "Epoch 989/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0371 - acc: 0.9942 - val_loss: 0.2793 - val_acc: 0.9610\n",
      "Epoch 990/1000\n",
      "10000/10000 [==============================] - 4s 379us/step - loss: 0.0409 - acc: 0.9942 - val_loss: 0.4054 - val_acc: 0.9520\n",
      "Epoch 991/1000\n",
      "10000/10000 [==============================] - 4s 385us/step - loss: 0.0427 - acc: 0.9933 - val_loss: 0.2886 - val_acc: 0.9590\n",
      "Epoch 992/1000\n",
      "10000/10000 [==============================] - 4s 378us/step - loss: 0.0377 - acc: 0.9930 - val_loss: 0.2750 - val_acc: 0.9650\n",
      "Epoch 993/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.0453 - acc: 0.9928 - val_loss: 0.2646 - val_acc: 0.9640\n",
      "Epoch 994/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0546 - acc: 0.9915 - val_loss: 0.4213 - val_acc: 0.9520\n",
      "Epoch 995/1000\n",
      "10000/10000 [==============================] - 4s 382us/step - loss: 0.0447 - acc: 0.9930 - val_loss: 0.2488 - val_acc: 0.9670\n",
      "Epoch 996/1000\n",
      "10000/10000 [==============================] - 4s 380us/step - loss: 0.0357 - acc: 0.9929 - val_loss: 0.3274 - val_acc: 0.9580\n",
      "Epoch 997/1000\n",
      "10000/10000 [==============================] - 4s 391us/step - loss: 0.0431 - acc: 0.9936 - val_loss: 0.3407 - val_acc: 0.9590\n",
      "Epoch 998/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.0439 - acc: 0.9934 - val_loss: 0.3132 - val_acc: 0.9610\n",
      "Epoch 999/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.0444 - acc: 0.9929 - val_loss: 0.3865 - val_acc: 0.9560\n",
      "Epoch 1000/1000\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.0341 - acc: 0.9942 - val_loss: 0.2868 - val_acc: 0.9610\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,questions_train],answers_train, batch_size = 32, epochs = 1000, validation_data = ([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../dataset/Z_chatbot_100_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets plot the increase of accuracy as we increase the number of training epochs\n",
    "#We can see that without any training the acc is about 50%, random guessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load a model that we have already trained and saved:\n",
    "model.load_weights('../dataset/Z_chatbot_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check out the predictions on the test set:\n",
    "#These are just probabilities for every single word on the vocab\n",
    "pred_results = model.predict(([inputs_test,questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First test data point\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.2288444e-14, 8.6332336e-14, 8.9146409e-14, 7.9060585e-14,\n",
       "       7.5501739e-14, 8.5093967e-14, 9.4845383e-14, 8.2923231e-14,\n",
       "       8.4691267e-14, 7.0612414e-14, 8.0247725e-14, 8.1863729e-14,\n",
       "       7.5649644e-14, 7.0855255e-14, 8.8028041e-14, 7.8170950e-14,\n",
       "       7.1597411e-14, 8.5324746e-14, 8.6697021e-14, 8.4206439e-14,\n",
       "       8.9837033e-14, 9.4251179e-14, 8.5709360e-14, 9.7819898e-14,\n",
       "       7.6218688e-14, 8.7112568e-14, 6.9840753e-14, 8.2436106e-14,\n",
       "       8.8672437e-14, 8.0188209e-14, 8.7820593e-14, 8.2125055e-14,\n",
       "       8.4437394e-14, 1.0000000e+00, 7.6480963e-14, 8.1816430e-14,\n",
       "       7.8662886e-14, 6.0389797e-11], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the probabilities for the vocab words using the 1st sentence\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See probability:\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, we can make our own questions using the vocabulary we have\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Sandra picked up the milk . Mary travelled left . '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra',\n",
       " 'picked',\n",
       " 'up',\n",
       " 'the',\n",
       " 'milk',\n",
       " '.',\n",
       " 'Mary',\n",
       " 'travelled',\n",
       " 'left',\n",
       " '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = 'Sandra got the milk ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra', 'got', 'the', 'milk', '?']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the data in the same format as before\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize this data\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the prediction\n",
    "pred_results = model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "#Correct prediction!\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994875"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confidence\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
