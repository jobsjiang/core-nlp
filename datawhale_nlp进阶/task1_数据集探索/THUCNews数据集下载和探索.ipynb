{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径设置\n",
    "base_dir = '../../../dataset/cnews/'\n",
    "train_dir = os.path.join(base_dir,'cnews.train.txt')\n",
    "test_dir = os.path.join(base_dir,'cnews.test.txt')\n",
    "val_dir = os.path.join(base_dir,'cnews.val.txt')\n",
    "vocab_dir = os.path.join(base_dir,'cnews.vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 功能函数\n",
    "# 打开文件\n",
    "def open_file(filename,mode='r'):\n",
    "    return open(filename,mode,encoding='utf-8')\n",
    "# 读取文件\n",
    "def read_file(filename):\n",
    "    contents,labels = [],[]\n",
    "    with open_file(filename) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                label,content = line.strip().split('\\t')\n",
    "                if content:\n",
    "                    contents.append(list(content))\n",
    "                    labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "        return contents,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据训练集构建词汇表，存储\n",
    "def build_vocab(train_dir,vocab_dir,vocab_size=5000):\n",
    "    data_train,_ = read_file(train_dir)\n",
    "    all_data = []\n",
    "    for content in data_train:\n",
    "        all_data.extend(content)\n",
    "    counter = Counter(all_data)\n",
    "    count_pairs = counter.most_common(vocab_size - 1) # 此处减去1是因为PAD占据0位\n",
    "    words,_ = list(zip(*count_pairs))\n",
    "    # 添加一个<PAD>来将所有文本pad为同一长度\n",
    "    words = ['<PAD>'] + list(words)\n",
    "    open_file(vocab_dir,mode='w').write('\\n'.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取词汇表\n",
    "def read_vocab(vocab_dir):\n",
    "    with open_file(vocab_dir) as f:\n",
    "        words = [_.strip() for _ in f.readlines()]\n",
    "    word_to_id = dict(zip(words,range(len(words))))\n",
    "    return words,word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取分类目录，目录固定\n",
    "def read_category():\n",
    "    categories = ['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n",
    "    cat_to_id = dict(zip(categories,range(len(categories))))\n",
    "    return categories,cat_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(content,words):\n",
    "    '''\n",
    "    将id表示的内容转换为文字\n",
    "    '''\n",
    "    return ''.join(words[x] for x in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename,word_to_id,cat_to_id,max_length=600):\n",
    "    '''\n",
    "    将文件转换为id表示\n",
    "    '''\n",
    "    contents,labels = read_file(filename)\n",
    "    data_id,label_id = [],[]\n",
    "    for i in range(len(contents)):\n",
    "        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n",
    "        label_id.append(cat_to_id[labels[i]])\n",
    "    print(type(label_id))\n",
    "    print(len(label_id))\n",
    "    # 使用keras提供的pad_sequences来将文本pad为固定长度\n",
    "    x_pad = keras.preprocessing.sequence.pad_sequences(data_id,max_length)\n",
    "    y_pad = keras.utils.to_categorical(label_id,num_classes=len(cat_to_id))\n",
    "    \n",
    "    return x_pad,y_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x,y,batch_size=64):\n",
    "    '''\n",
    "    生成批次数据\n",
    "    '''\n",
    "    data_len = len(x)\n",
    "    num_batch = int((data_len - 1)/batch_size) + 1\n",
    "    \n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuffle = x[indices]\n",
    "    y_shuffle = y[indices]\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size,data_len)\n",
    "        yield x_shuffle[start_id:end_id],y_shuffle[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 50000\n",
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "# 数据探索 ，读取文本，查看文本信息\n",
    "x_ori,y_ori = read_file(train_dir)\n",
    "print(len(x_ori),len(y_ori))\n",
    "x_val_ori,y_val_ori = read_file(val_dir)\n",
    "print(len(x_val_ori),len(y_val_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词汇表(数据集中已有)\n",
    "# build_vocab(train_dir, vocab_dir, vocab_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "# 读取分类目录\n",
    "categories,cat_to_id = read_category()\n",
    "print(len(categories),len(cat_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "体育:5000\n",
      "财经:5000\n",
      "房产:5000\n",
      "家居:5000\n",
      "教育:5000\n",
      "科技:5000\n",
      "时尚:5000\n",
      "时政:5000\n",
      "游戏:5000\n",
      "娱乐:5000\n",
      "--------------------------------------------------\n",
      "体育:500\n",
      "财经:500\n",
      "房产:500\n",
      "家居:500\n",
      "教育:500\n",
      "科技:500\n",
      "时尚:500\n",
      "时政:500\n",
      "游戏:500\n",
      "娱乐:500\n"
     ]
    }
   ],
   "source": [
    "# 输出类的个数\n",
    "# 训练集\n",
    "for i in categories:\n",
    "    print(str(i) + \":\" + str(y_ori.count(i)))\n",
    "print(\"-\"*50)\n",
    "# 验证集\n",
    "for i in categories:\n",
    "    print(str(i) + \":\" + str(y_val_ori.count(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取词汇表\n",
    "words,word_to_id = read_vocab(vocab_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 4998\n"
     ]
    }
   ],
   "source": [
    "print(len(words),len(word_to_id)) # 由于words中有重复的元素导致长度不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = (str(k) + \":\" + str(v) for k,v in dict(Counter(words).items()) if v > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 3)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "50000\n",
      "<class 'list'>\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# 建立训练集和测试集，将文本转换为id的形式，便于后续放入网络中\n",
    "x_train,y_train = process_file(train_dir,word_to_id,cat_to_id,max_length=600)\n",
    "x_val,y_val = process_file(val_dir,word_to_id,cat_to_id,max_length=600)\n",
    "# print(x_train[0])\n",
    "# print(y_train[0])\n",
    "# print([len(x_train[i]) for i in range(3)])  # 查看单句长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沈阳就有大雨，但幸好队伍上午的训练并没有受到任何干扰。下午6点，当球队抵达训练场时，大雨已经下了几个小时，而且丝毫没有停下来的意思。抱着试一试的态度，球队开始了当天下午的例行训练，25分钟过去了，天气没有任何转好的迹象，为了保护球员们，国奥队决定中止当天的训练，全队立即返回酒店。在雨中训练对足球队来说并不是什么稀罕事，但在奥运会即将开始之前，全队变得“娇贵”了。在沈阳最后一周的训练，国奥队首先要保证现有的球员不再出现意外的伤病情况以免影响正式比赛，因此这一阶段控制训练受伤、控制感冒等疾病的出现被队伍放在了相当重要的位置。而抵达沈阳之后，中后卫冯萧霆就一直没有训练，冯萧霆是7月27日在长春患上了感冒，因此也没有参加29日跟塞尔维亚的热身赛。队伍介绍说，冯萧霆并没有出现发烧症状，但为了安全起见，这两天还是让他静养休息，等感冒彻底好了之后再恢复训练。由于有了冯萧霆这个例子，因此国奥队对雨中训练就显得特别谨慎，主要是担心球员们受凉而引发感冒，造成非战斗减员。而女足队员马晓旭在热身赛中受伤导致无缘奥运的前科，也让在沈阳的国奥队现在格外警惕，“训练中不断嘱咐队员们要注意动作，我们可不能再出这样的事情了。”一位工作人员表示。从长春到沈阳，雨水一路伴随着国奥队，“也邪了，我们走到哪儿雨就下到哪儿，在长春几次训练都被大雨给搅和了，没想到来沈阳又碰到这种事情。”一位国奥球员也对雨水的“青睐”有些不解。\n"
     ]
    }
   ],
   "source": [
    "# 将id的形式转换为文本\n",
    "print(to_words(x_train[0],words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
