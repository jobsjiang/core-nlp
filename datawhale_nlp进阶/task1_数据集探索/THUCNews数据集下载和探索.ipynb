{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jianghaitao1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径设置\n",
    "base_dir = '../../../dataset/cnews/'\n",
    "train_dir = os.path.join(base_dir,'cnews.train.txt')\n",
    "test_dir = os.path.join(base_dir,'cnews.test.txt')\n",
    "val_dir = os.path.join(base_dir,'cnews.val.txt')\n",
    "vocab_dir = os.path.join(base_dir,'cnews.vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 功能函数\n",
    "# 打开文件\n",
    "def open_file(filename,mode='r'):\n",
    "    return open(filename,mode,encoding='utf-8')\n",
    "# 读取文件\n",
    "def read_file(filename):\n",
    "    contents,labels = [],[]\n",
    "    with open_file(filename) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                label,content = line.strip().split('\\t')\n",
    "                if content:\n",
    "                    contents.append(list(content))\n",
    "                    labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "        return contents,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据训练集构建词汇表，存储\n",
    "def build_vocab(train_dir,vocab_dir,vocab_size=5000):\n",
    "    data_train,_ = read_file(train_dir)\n",
    "    all_data = []\n",
    "    for content in data_train:\n",
    "        all_data.extend(content)\n",
    "    counter = Counter(all_data)\n",
    "    count_pairs = counter.most_common(vocab_size - 1) # 此处减去1是因为PAD占据0位\n",
    "    words,_ = list(zip(*count_pairs))\n",
    "    # 添加一个<PAD>来将所有文本pad为同一长度\n",
    "    words = ['<PAD>'] + list(words)\n",
    "    open_file(vocab_dir,mode='w').write('\\n'.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取词汇表\n",
    "def read_vocab(vocab_dir):\n",
    "    with open_file(vocab_dir) as f:\n",
    "        words = [_.strip() for _ in f.readlines()]\n",
    "    word_to_id = dict(zip(words,range(len(words))))\n",
    "    return words,word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取分类目录，目录固定\n",
    "def read_category():\n",
    "    categories = ['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n",
    "    cat_to_id = dict(zip(categories,range(len(categories))))\n",
    "    return categories,cat_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(content,words):\n",
    "    '''\n",
    "    将id表示的内容转换为文字\n",
    "    '''\n",
    "    return ''.join(words[x] for x in content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename,word_to_id,cat_to_id,max_length=600):\n",
    "    '''\n",
    "    将文件转换为id表示\n",
    "    '''\n",
    "    contents,labels = read_file(filename)\n",
    "    data_id,label_id = [],[]\n",
    "    for i in range(len(contents)):\n",
    "        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])\n",
    "        label_id.append(cat_to_id[labels[i]])\n",
    "    # 使用keras提供的pad_sequences来将文本pad为固定长度\n",
    "    x_pad = keras.preprocessing.sequence.pad_sequences(data_id,max_length)\n",
    "    y_pad = keras.preprocessing.sequence.pad_sequences(label_id,num_classes=len(cat_to_id))\n",
    "    \n",
    "    return x_pad,y_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(x,y,batch_size=64):\n",
    "    '''\n",
    "    生成批次数据\n",
    "    '''\n",
    "    data_len = len(x)\n",
    "    num_batch = int((data_len - 1)/batch_size) + 1\n",
    "    \n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuffle = x[indices]\n",
    "    y_shuffle = y[indices]\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        start_id = i * batch_size\n",
    "        end_id = min((i + 1) * batch_size,data_len)\n",
    "        yield x_shuffle[start_id:end_id],y_shuffle[start_id:end_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
