{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将字母转换为小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"The 5 biggest countries by population in 2017 are China, India, United States, Indonesia, and Brazil.\"\n",
    "input_str = input_str.lower()\n",
    "print(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 删除数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "input_str = \"Box A contains 3 red and 5 white balls,while Box B contains 4 red and 2 blue balls.\"\n",
    "result = re.sub(r'\\d+','',input_str)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 删除标点符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "input_str = \"This &is [an] example? {of} string.with.? punctuation!!!!\"\n",
    "result = input_str.translate(string.maketrans(\"\",\" \"),string.punctuation)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 刪除空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \" \\t a string example\\t \"\n",
    "input_str = input_str.strip()\n",
    "print(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 刪除停止词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "input_str = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = word_tokenize(input_str)\n",
    "result = [i for i in tokens if not i in stop_words]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stemming\n",
    "Stemming 是将单词减为词干、词根或词干的过程。根表单（例如，books-book、looked-look）。主要两个算法是 Porter stemming algorithm（从单词中删除常见的词尾）和 Lancaster stemming algorithm（一种更具攻击性的词干算法）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer = PorterStemmer()\n",
    "input_str = \"There are several types of stemming algorithms.\"\n",
    "input_str = word_tokenize(input_str)\n",
    "for word in input_str:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Lemmatization\n",
    "Lemmatization 与 Stemming 功能相似，但作用相反。它不是简单地切掉词干。相反，它使用词汇知识获取正确单词基本形式的基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "input_str = \"been had done languages cities mice\"\n",
    "input_str = word_tokenize(input_str)\n",
    "for word in input_str:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 语音标记部分\n",
    "词性标记的一部分旨在将词性部分分配给基于它的给定文本（如名词、动词、形容词和其他）定义及其上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "input_str = \"Parts of speech examples: an article, to write, interesting, easily, and, of\"\n",
    "result = TextBlob(input_str)\n",
    "print(result.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 分块（浅解析）\n",
    "分块是一种自然的语言过程，用于识别组成部分把句子（名词、动词、形容词等）联系起来具有离散语法意义的顺序单位（名词组或短语、动词组等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "input_str = \"A black television and a white stove were bought for the new apartment of John.\"\n",
    "result = TextBlob(input_str)\n",
    "print(result.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 命名实体识别\n",
    "命名实体识别（NER）旨在在文本中查找命名实体并将其分为预先定义的类别（人员姓名，地点、组织、时间等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "input_str = \"Bill works for Apple so he went to Boston for a conference.\"\n",
    "print(ne_chunk(pos_tag(word_tokenize(input_str))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. 词搭配提取\n",
    "搭配是经常出现在一起的单词组合。例如 “break the rules,” “free time,” “draw a conclusion,” “keep in mind,” “get ready,” 等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ICE import CollocationExtractor\n",
    "input = [\"he and Chazz duel with all keys on the line.\"]\n",
    "extractor = CollocationExtractor.with_collocation_pipeline(\n",
    "    \"T1\", bing_key=\"Temp\", pos_check=False)\n",
    "print(extractor.get_collocations_of_length(input, length=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
